{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b650e484",
   "metadata": {},
   "source": [
    "# Pandas Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8cd3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43392a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "a=[\"Yaswanth\",\"Abhishek\",\"Shimlan\"]\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4009b548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "       Name\n",
      "0  Yaswanth\n",
      "1  Abhishek\n",
      "2   Shimlan\n"
     ]
    }
   ],
   "source": [
    "a={\"Name\" : [\"Yaswanth\",\"Abhishek\",\"Shimlan\"]}\n",
    "data=pd.DataFrame(a)\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d1226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "       Name  Age    Sal\n",
      "0  Yaswanth   22  50000\n",
      "1  Abhishek   23  60000\n",
      "2   Shimlan   23  70000\n"
     ]
    }
   ],
   "source": [
    "a={\"Name\" : [\"Yaswanth\",\"Abhishek\",\"Shimlan\"],\n",
    "   \"Age\" : [22,23,23],\n",
    "   \"Sal\" : [50000,60000,70000]}\n",
    "data=pd.DataFrame(a)\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56e863",
   "metadata": {},
   "source": [
    "# Program2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574919b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c7684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crop     year   area     msp  yields\n",
      "0            rice  2014-15  15759    1360  378216\n",
      "1            rice  2015-16  15987    1414  383688\n",
      "2            rice  2016-17  15747    1470  377928\n",
      "3            rice  2017-18  15958    1550  382992\n",
      "4            rice  2018-19  15848    1750  380352\n",
      "..            ...      ...    ...     ...     ...\n",
      "95  errachandanam  2014-15      5  150000      10\n",
      "96  errachandanam  2015-16      5  160000      10\n",
      "97  errachandanam  2016-17      9  190000      10\n",
      "98  errachandanam  2017-18     10  195000      10\n",
      "99  errachandanam  2018-19     12  209000      10\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/crops.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120a8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crop     year   area     msp  yields\n",
      "0            rice  2014-15  15759    1360  378216\n",
      "1            rice  2015-16  15987    1414  383688\n",
      "2            rice  2016-17  15747    1470  377928\n",
      "3            rice  2017-18  15958    1550  382992\n",
      "4            rice  2018-19  15848    1750  380352\n",
      "5           maize  2014-15   1199    1310   29975\n",
      "6           maize  2015-16   1227    1325   30675\n",
      "7           maize  2016-17   1325    1365   33125\n",
      "8           maize  2017-18   1369    1425   34225\n",
      "9           maize  2018-19    951    1700   23775\n",
      "10      greengram  2014-15     45    4600     225\n",
      "11      greengram  2015-16     40    4850     200\n",
      "12      greengram  2016-17     51    5225     255\n",
      "13      greengram  2017-18     40    5575     200\n",
      "14      greengram  2018-19     38    6975     190\n",
      "15        redgram  2014-15     27    3175     168\n",
      "16       red gram  2015-16     12    3500      72\n",
      "17       red gram  2016-17     16    4000      80\n",
      "18       red gram  2017-18     33    4400     165\n",
      "19       red gram  2018-19     30    4600     150\n",
      "20         cotton  2014-15    183    3750    1098\n",
      "21         cotton  2015-16    176    3800    1056\n",
      "22         cotton  2016-17    135    3860     810\n",
      "23         cotton  2017-18    157    4020     942\n",
      "24         cotton  2018-19     79    5150     474\n",
      "25       turmeric  2014-15      3       2      30\n",
      "26       turmeric  2015-16      7       2      70\n",
      "27       turmeric  2016-17      2       2      20\n",
      "28       turmeric  2017-18      3       2      30\n",
      "29       turmeric  2018-19      6       2      60\n",
      "30      sugarcane  2014-15   2627     220  525400\n",
      "31      sugarcane  2015-16   1863     230  372600\n",
      "32      sugarcane  2016-17   1711     230  342200\n",
      "33      sugarcane  2017-18   1448     255  289600\n",
      "34      sugarcane  2018-19   1266     275  253200\n",
      "35          mango  2014-15   3408   10000   51015\n",
      "36          mango  2015-16   2527   10100   37905\n",
      "37          mango  2016-17   2092   11000   31380\n",
      "38          mango  2017-18   1829   11500   87435\n",
      "39          mango  2018-19   1627   13000   24405\n",
      "40     cashew nut  2014-15    284   10000     568\n",
      "41     cashew nut  2015-16    254   11000     508\n",
      "42     cashew nut  2016-17    223   12000     446\n",
      "43     cashew nut  2017-18    226   13000     452\n",
      "44     cashew nut  2018-19    189   19000     378\n",
      "45         banana  2014-15    116    6000   18560\n",
      "46         banana  2015-16    235    7000   43600\n",
      "47         banana  2016-17     76    9000   12160\n",
      "48         banana  2017-18     70   10000   11200\n",
      "49         banana  2018-19     36   15000    5760\n",
      "50          guava  2014-15    176    9000    1760\n",
      "51          guava  2015-16    242    9500    2420\n",
      "52          guava  2016-17    302    9600    3020\n",
      "53          guava  2017-18    345    9700    3450\n",
      "54          guava  2018-19    363   10000    3630\n",
      "55          lemon  2014-15     49   15000     245\n",
      "56          lemon  2015-16     54   15500     270\n",
      "57          lemon  2016-17     67   16000     335\n",
      "58          lemon  2017-18     95   17000     475\n",
      "59          lemon  2018-19     95   17500     475\n",
      "60        coconut  2014-15    188    1450   56400\n",
      "61        coconut  2015-16    169    1500   50700\n",
      "62        coconut  2016-17    137    1600   41100\n",
      "63        coconut  2017-18    152    1760   45600\n",
      "64        coconut  2018-19    155    2030   46100\n",
      "65         sapota  2014-15     21    6000     840\n",
      "66         sapota  2015-16     79    5000    3160\n",
      "67         sapota  2016-17     68    5500    2720\n",
      "68         sapota  2017-18     74    6200    2960\n",
      "69         sapota  2018-19     70    6500    2800\n",
      "70        palmoil  2014-15   1487   30000  386620\n",
      "71        palmoil  2015-16   1792   35000  465920\n",
      "72        palmoil  2016-17   1866   36000  485160\n",
      "73        palmoil  2017-18   1915   38000  497900\n",
      "74        palmoil  2018-19   1955   40000  508300\n",
      "75      eukalptus  2014-15   2003    8000  460690\n",
      "76      eukalptus  2015-16   2548    8500  586040\n",
      "77      eukalytus  2016-17   2585    9000  594550\n",
      "78      eukalytus  2017-18   2664    9500  612720\n",
      "79      eukalytus  2018-19   2668   10000  613640\n",
      "80        malbari  2014-15      5   90000    2250\n",
      "81        malbari  2015-16      5   80000    2850\n",
      "82        malbari  2016-17     19   60000    8550\n",
      "83        malbari  2017-18     17   85000    7650\n",
      "84        malbari  2018-19     19   90000    8559\n",
      "85     chedu vepa  2014-15     15   56000    3750\n",
      "86     chedu vepa  2015-16     15   59000    3750\n",
      "87     chedu vepa  2016-17     15   65000    3750\n",
      "88     chedu vepa  2017-18     19   67000    4750\n",
      "89     chedu vepa  2018-19     19   75000    4750\n",
      "90          tekku  2014-15     25  150000      10\n",
      "91          tekku  2015-16     32  160000      10\n",
      "92          tekku  2016-17     34  175000      10\n",
      "93          tekku  2017-18     40  189000      10\n",
      "94          tekku  2018-19     40  190000      10\n",
      "95  errachandanam  2014-15      5  150000      10\n",
      "96  errachandanam  2015-16      5  160000      10\n",
      "97  errachandanam  2016-17      9  190000      10\n",
      "98  errachandanam  2017-18     10  195000      10\n",
      "99  errachandanam  2018-19     12  209000      10\n"
     ]
    }
   ],
   "source": [
    "#To print the entire DataFrame\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02246b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5.1  3.5  1.4  0.2     Iris-setosa\n",
      "0    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "1    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "2    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "3    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "4    5.4  3.9  1.7  0.4     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "144  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "145  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "146  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "147  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "148  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[149 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/iris.data\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4094e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature 1  Feature 2  Feature 3  Feature 4          Result\n",
      "0          5.1        3.5        1.4        0.2     Iris-setosa\n",
      "1          4.9        3.0        1.4        0.2     Iris-setosa\n",
      "2          4.7        3.2        1.3        0.2     Iris-setosa\n",
      "3          4.6        3.1        1.5        0.2     Iris-setosa\n",
      "4          5.0        3.6        1.4        0.2     Iris-setosa\n",
      "..         ...        ...        ...        ...             ...\n",
      "145        6.7        3.0        5.2        2.3  Iris-virginica\n",
      "146        6.3        2.5        5.0        1.9  Iris-virginica\n",
      "147        6.5        3.0        5.2        2.0  Iris-virginica\n",
      "148        6.2        3.4        5.4        2.3  Iris-virginica\n",
      "149        5.9        3.0        5.1        1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/iris.data\", names=[\"Feature 1\",\"Feature 2\",\"Feature 3\",\"Feature 4\",\"Result\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b73ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature 1  Feature 2  Feature 3  Feature 4           Result\n",
      "0          5.1        3.5        1.4        0.2      Iris-setosa\n",
      "1          4.9        3.0        1.4        0.2      Iris-setosa\n",
      "2          4.7        3.2        1.3        0.2      Iris-setosa\n",
      "3          4.6        3.1        1.5        0.2      Iris-setosa\n",
      "4          5.0        3.6        1.4        0.2      Iris-setosa\n",
      "5          5.4        3.9        1.7        0.4      Iris-setosa\n",
      "6          4.6        3.4        1.4        0.3      Iris-setosa\n",
      "7          5.0        3.4        1.5        0.2      Iris-setosa\n",
      "8          4.4        2.9        1.4        0.2      Iris-setosa\n",
      "9          4.9        3.1        1.5        0.1      Iris-setosa\n",
      "10         5.4        3.7        1.5        0.2      Iris-setosa\n",
      "11         4.8        3.4        1.6        0.2      Iris-setosa\n",
      "12         4.8        3.0        1.4        0.1      Iris-setosa\n",
      "13         4.3        3.0        1.1        0.1      Iris-setosa\n",
      "14         5.8        4.0        1.2        0.2      Iris-setosa\n",
      "15         5.7        4.4        1.5        0.4      Iris-setosa\n",
      "16         5.4        3.9        1.3        0.4      Iris-setosa\n",
      "17         5.1        3.5        1.4        0.3      Iris-setosa\n",
      "18         5.7        3.8        1.7        0.3      Iris-setosa\n",
      "19         5.1        3.8        1.5        0.3      Iris-setosa\n",
      "20         5.4        3.4        1.7        0.2      Iris-setosa\n",
      "21         5.1        3.7        1.5        0.4      Iris-setosa\n",
      "22         4.6        3.6        1.0        0.2      Iris-setosa\n",
      "23         5.1        3.3        1.7        0.5      Iris-setosa\n",
      "24         4.8        3.4        1.9        0.2      Iris-setosa\n",
      "25         5.0        3.0        1.6        0.2      Iris-setosa\n",
      "26         5.0        3.4        1.6        0.4      Iris-setosa\n",
      "27         5.2        3.5        1.5        0.2      Iris-setosa\n",
      "28         5.2        3.4        1.4        0.2      Iris-setosa\n",
      "29         4.7        3.2        1.6        0.2      Iris-setosa\n",
      "30         4.8        3.1        1.6        0.2      Iris-setosa\n",
      "31         5.4        3.4        1.5        0.4      Iris-setosa\n",
      "32         5.2        4.1        1.5        0.1      Iris-setosa\n",
      "33         5.5        4.2        1.4        0.2      Iris-setosa\n",
      "34         4.9        3.1        1.5        0.1      Iris-setosa\n",
      "35         5.0        3.2        1.2        0.2      Iris-setosa\n",
      "36         5.5        3.5        1.3        0.2      Iris-setosa\n",
      "37         4.9        3.1        1.5        0.1      Iris-setosa\n",
      "38         4.4        3.0        1.3        0.2      Iris-setosa\n",
      "39         5.1        3.4        1.5        0.2      Iris-setosa\n",
      "40         5.0        3.5        1.3        0.3      Iris-setosa\n",
      "41         4.5        2.3        1.3        0.3      Iris-setosa\n",
      "42         4.4        3.2        1.3        0.2      Iris-setosa\n",
      "43         5.0        3.5        1.6        0.6      Iris-setosa\n",
      "44         5.1        3.8        1.9        0.4      Iris-setosa\n",
      "45         4.8        3.0        1.4        0.3      Iris-setosa\n",
      "46         5.1        3.8        1.6        0.2      Iris-setosa\n",
      "47         4.6        3.2        1.4        0.2      Iris-setosa\n",
      "48         5.3        3.7        1.5        0.2      Iris-setosa\n",
      "49         5.0        3.3        1.4        0.2      Iris-setosa\n",
      "50         7.0        3.2        4.7        1.4  Iris-versicolor\n",
      "51         6.4        3.2        4.5        1.5  Iris-versicolor\n",
      "52         6.9        3.1        4.9        1.5  Iris-versicolor\n",
      "53         5.5        2.3        4.0        1.3  Iris-versicolor\n",
      "54         6.5        2.8        4.6        1.5  Iris-versicolor\n",
      "55         5.7        2.8        4.5        1.3  Iris-versicolor\n",
      "56         6.3        3.3        4.7        1.6  Iris-versicolor\n",
      "57         4.9        2.4        3.3        1.0  Iris-versicolor\n",
      "58         6.6        2.9        4.6        1.3  Iris-versicolor\n",
      "59         5.2        2.7        3.9        1.4  Iris-versicolor\n",
      "60         5.0        2.0        3.5        1.0  Iris-versicolor\n",
      "61         5.9        3.0        4.2        1.5  Iris-versicolor\n",
      "62         6.0        2.2        4.0        1.0  Iris-versicolor\n",
      "63         6.1        2.9        4.7        1.4  Iris-versicolor\n",
      "64         5.6        2.9        3.6        1.3  Iris-versicolor\n",
      "65         6.7        3.1        4.4        1.4  Iris-versicolor\n",
      "66         5.6        3.0        4.5        1.5  Iris-versicolor\n",
      "67         5.8        2.7        4.1        1.0  Iris-versicolor\n",
      "68         6.2        2.2        4.5        1.5  Iris-versicolor\n",
      "69         5.6        2.5        3.9        1.1  Iris-versicolor\n",
      "70         5.9        3.2        4.8        1.8  Iris-versicolor\n",
      "71         6.1        2.8        4.0        1.3  Iris-versicolor\n",
      "72         6.3        2.5        4.9        1.5  Iris-versicolor\n",
      "73         6.1        2.8        4.7        1.2  Iris-versicolor\n",
      "74         6.4        2.9        4.3        1.3  Iris-versicolor\n",
      "75         6.6        3.0        4.4        1.4  Iris-versicolor\n",
      "76         6.8        2.8        4.8        1.4  Iris-versicolor\n",
      "77         6.7        3.0        5.0        1.7  Iris-versicolor\n",
      "78         6.0        2.9        4.5        1.5  Iris-versicolor\n",
      "79         5.7        2.6        3.5        1.0  Iris-versicolor\n",
      "80         5.5        2.4        3.8        1.1  Iris-versicolor\n",
      "81         5.5        2.4        3.7        1.0  Iris-versicolor\n",
      "82         5.8        2.7        3.9        1.2  Iris-versicolor\n",
      "83         6.0        2.7        5.1        1.6  Iris-versicolor\n",
      "84         5.4        3.0        4.5        1.5  Iris-versicolor\n",
      "85         6.0        3.4        4.5        1.6  Iris-versicolor\n",
      "86         6.7        3.1        4.7        1.5  Iris-versicolor\n",
      "87         6.3        2.3        4.4        1.3  Iris-versicolor\n",
      "88         5.6        3.0        4.1        1.3  Iris-versicolor\n",
      "89         5.5        2.5        4.0        1.3  Iris-versicolor\n",
      "90         5.5        2.6        4.4        1.2  Iris-versicolor\n",
      "91         6.1        3.0        4.6        1.4  Iris-versicolor\n",
      "92         5.8        2.6        4.0        1.2  Iris-versicolor\n",
      "93         5.0        2.3        3.3        1.0  Iris-versicolor\n",
      "94         5.6        2.7        4.2        1.3  Iris-versicolor\n",
      "95         5.7        3.0        4.2        1.2  Iris-versicolor\n",
      "96         5.7        2.9        4.2        1.3  Iris-versicolor\n",
      "97         6.2        2.9        4.3        1.3  Iris-versicolor\n",
      "98         5.1        2.5        3.0        1.1  Iris-versicolor\n",
      "99         5.7        2.8        4.1        1.3  Iris-versicolor\n",
      "100        6.3        3.3        6.0        2.5   Iris-virginica\n",
      "101        5.8        2.7        5.1        1.9   Iris-virginica\n",
      "102        7.1        3.0        5.9        2.1   Iris-virginica\n",
      "103        6.3        2.9        5.6        1.8   Iris-virginica\n",
      "104        6.5        3.0        5.8        2.2   Iris-virginica\n",
      "105        7.6        3.0        6.6        2.1   Iris-virginica\n",
      "106        4.9        2.5        4.5        1.7   Iris-virginica\n",
      "107        7.3        2.9        6.3        1.8   Iris-virginica\n",
      "108        6.7        2.5        5.8        1.8   Iris-virginica\n",
      "109        7.2        3.6        6.1        2.5   Iris-virginica\n",
      "110        6.5        3.2        5.1        2.0   Iris-virginica\n",
      "111        6.4        2.7        5.3        1.9   Iris-virginica\n",
      "112        6.8        3.0        5.5        2.1   Iris-virginica\n",
      "113        5.7        2.5        5.0        2.0   Iris-virginica\n",
      "114        5.8        2.8        5.1        2.4   Iris-virginica\n",
      "115        6.4        3.2        5.3        2.3   Iris-virginica\n",
      "116        6.5        3.0        5.5        1.8   Iris-virginica\n",
      "117        7.7        3.8        6.7        2.2   Iris-virginica\n",
      "118        7.7        2.6        6.9        2.3   Iris-virginica\n",
      "119        6.0        2.2        5.0        1.5   Iris-virginica\n",
      "120        6.9        3.2        5.7        2.3   Iris-virginica\n",
      "121        5.6        2.8        4.9        2.0   Iris-virginica\n",
      "122        7.7        2.8        6.7        2.0   Iris-virginica\n",
      "123        6.3        2.7        4.9        1.8   Iris-virginica\n",
      "124        6.7        3.3        5.7        2.1   Iris-virginica\n",
      "125        7.2        3.2        6.0        1.8   Iris-virginica\n",
      "126        6.2        2.8        4.8        1.8   Iris-virginica\n",
      "127        6.1        3.0        4.9        1.8   Iris-virginica\n",
      "128        6.4        2.8        5.6        2.1   Iris-virginica\n",
      "129        7.2        3.0        5.8        1.6   Iris-virginica\n",
      "130        7.4        2.8        6.1        1.9   Iris-virginica\n",
      "131        7.9        3.8        6.4        2.0   Iris-virginica\n",
      "132        6.4        2.8        5.6        2.2   Iris-virginica\n",
      "133        6.3        2.8        5.1        1.5   Iris-virginica\n",
      "134        6.1        2.6        5.6        1.4   Iris-virginica\n",
      "135        7.7        3.0        6.1        2.3   Iris-virginica\n",
      "136        6.3        3.4        5.6        2.4   Iris-virginica\n",
      "137        6.4        3.1        5.5        1.8   Iris-virginica\n",
      "138        6.0        3.0        4.8        1.8   Iris-virginica\n",
      "139        6.9        3.1        5.4        2.1   Iris-virginica\n",
      "140        6.7        3.1        5.6        2.4   Iris-virginica\n",
      "141        6.9        3.1        5.1        2.3   Iris-virginica\n",
      "142        5.8        2.7        5.1        1.9   Iris-virginica\n",
      "143        6.8        3.2        5.9        2.3   Iris-virginica\n",
      "144        6.7        3.3        5.7        2.5   Iris-virginica\n",
      "145        6.7        3.0        5.2        2.3   Iris-virginica\n",
      "146        6.3        2.5        5.0        1.9   Iris-virginica\n",
      "147        6.5        3.0        5.2        2.0   Iris-virginica\n",
      "148        6.2        3.4        5.4        2.3   Iris-virginica\n",
      "149        5.9        3.0        5.1        1.8   Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/iris.data\", names=[\"Feature 1\",\"Feature 2\",\"Feature 3\",\"Feature 4\",\"Result\"])\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d4be2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
      "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
      "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
      "\n",
      "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0    ...      4        3      4     1     1      3        6   5   6   6  \n",
      "1    ...      5        3      3     1     1      3        4   5   5   6  \n",
      "2    ...      4        3      2     2     3      3       10   7   8  10  \n",
      "3    ...      3        2      2     1     1      5        2  15  14  15  \n",
      "4    ...      4        3      2     1     2      5        4   6  10  10  \n",
      "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
      "390  ...      5        5      4     4     5      4       11   9   9   9  \n",
      "391  ...      2        4      5     3     4      2        3  14  16  16  \n",
      "392  ...      5        5      3     3     3      3        3  10   8   7  \n",
      "393  ...      4        4      1     3     4      5        0  11  12  10  \n",
      "394  ...      3        2      3     3     3      5        5   8   9   9  \n",
      "\n",
      "[395 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/student-mat.csv\", delimiter=\";\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6497caee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       FL_DATE OP_UNIQUE_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  DEP_DELAY  \\\n",
      "0   2019-01-01                9E               5246    MSP  MKE         33   \n",
      "1   2019-01-01                9E               5249    ATL  PHF          8   \n",
      "2   2019-01-01                9E               5249    PHF  ATL         -6   \n",
      "3   2019-01-01                9E               5250    MSP  CLE         10   \n",
      "4   2019-01-01                9E               5254    MSP  RDU         -5   \n",
      "..         ...               ...                ...    ...  ...        ...   \n",
      "194 2019-01-01                AA                459    SEA  PHX         -1   \n",
      "195 2019-01-01                AA                460    PHX  ORD          3   \n",
      "196 2019-01-01                AA                461    MCO  CLT         11   \n",
      "197 2019-01-01                AA                462    PHX  ATL         -2   \n",
      "198 2019-01-01                AA                463    MCO  PHX          8   \n",
      "\n",
      "     ARR_DELAY  CANCELLED  ACTUAL_ELAPSED_TIME  \n",
      "0            8          0                   64  \n",
      "1           -5          0                   90  \n",
      "2           -2          0                  121  \n",
      "3           -5          0                  102  \n",
      "4          -27          0                  139  \n",
      "..         ...        ...                  ...  \n",
      "194         33          0                  206  \n",
      "195         -5          0                  204  \n",
      "196          9          0                  104  \n",
      "197         -2          0                  206  \n",
      "198          7          0                  284  \n",
      "\n",
      "[199 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel(\"Data/sampleexcel.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeaaf841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  name   phone address    m1    m2    m3    m4\n",
      "0    101  anand    999     hyd  87.0  55.0   NaN  44.0\n",
      "1    105    aaa    555     vij  77.0  66.0  99.0  99.0\n",
      "2    109    rrr    444     vik   NaN  78.0  88.0  88.0\n",
      "3    107    sss    888     sec  69.0  85.0  58.0   NaN\n",
      "4    102    bbb    111     ant  89.0   NaN  99.0  99.0\n",
      "5    201  anand    999     hyd  87.0  55.0   NaN  44.0\n",
      "6    202    aaa    555     vij   NaN  66.0  99.0   NaN\n",
      "7    203    rrr    444     vik  89.0  78.0  88.0  88.0\n",
      "8    204    NaN    888     NaN  33.0  77.0  58.0   NaN\n",
      "9    205    bbb    111     ant  77.0  88.0  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel(\"Data/sampleexcel.xlsx\", sheet_name = \"chetan\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b29ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  season        city        date                  team1  \\\n",
      "0      1    2008   Bangalore  2008-04-18  Kolkata Knight Riders   \n",
      "1      2    2008  Chandigarh  2008-04-19    Chennai Super Kings   \n",
      "2      3    2008       Delhi  2008-04-19       Rajasthan Royals   \n",
      "3      4    2008      Mumbai  2008-04-20         Mumbai Indians   \n",
      "4      5    2008     Kolkata  2008-04-20        Deccan Chargers   \n",
      "..   ...     ...         ...         ...                    ...   \n",
      "572  573    2016      Raipur  2016-05-22       Delhi Daredevils   \n",
      "573  574    2016   Bangalore  2016-05-24          Gujarat Lions   \n",
      "574  575    2016       Delhi  2016-05-25    Sunrisers Hyderabad   \n",
      "575  576    2016       Delhi  2016-05-27          Gujarat Lions   \n",
      "576  577    2016   Bangalore  2016-05-29    Sunrisers Hyderabad   \n",
      "\n",
      "                           team2                  toss_winner toss_decision  \\\n",
      "0    Royal Challengers Bangalore  Royal Challengers Bangalore         field   \n",
      "1                Kings XI Punjab          Chennai Super Kings           bat   \n",
      "2               Delhi Daredevils             Rajasthan Royals           bat   \n",
      "3    Royal Challengers Bangalore               Mumbai Indians           bat   \n",
      "4          Kolkata Knight Riders              Deccan Chargers           bat   \n",
      "..                           ...                          ...           ...   \n",
      "572  Royal Challengers Bangalore  Royal Challengers Bangalore         field   \n",
      "573  Royal Challengers Bangalore  Royal Challengers Bangalore         field   \n",
      "574        Kolkata Knight Riders        Kolkata Knight Riders         field   \n",
      "575          Sunrisers Hyderabad          Sunrisers Hyderabad         field   \n",
      "576  Royal Challengers Bangalore          Sunrisers Hyderabad           bat   \n",
      "\n",
      "     result  dl_applied                       winner  win_by_runs  \\\n",
      "0    normal           0        Kolkata Knight Riders          140   \n",
      "1    normal           0          Chennai Super Kings           33   \n",
      "2    normal           0             Delhi Daredevils            0   \n",
      "3    normal           0  Royal Challengers Bangalore            0   \n",
      "4    normal           0        Kolkata Knight Riders            0   \n",
      "..      ...         ...                          ...          ...   \n",
      "572  normal           0  Royal Challengers Bangalore            0   \n",
      "573  normal           0  Royal Challengers Bangalore            0   \n",
      "574  normal           0          Sunrisers Hyderabad           22   \n",
      "575  normal           0          Sunrisers Hyderabad            0   \n",
      "576  normal           0          Sunrisers Hyderabad            8   \n",
      "\n",
      "     win_by_wickets player_of_match  \\\n",
      "0                 0     BB McCullum   \n",
      "1                 0      MEK Hussey   \n",
      "2                 9     MF Maharoof   \n",
      "3                 5      MV Boucher   \n",
      "4                 5       DJ Hussey   \n",
      "..              ...             ...   \n",
      "572               6         V Kohli   \n",
      "573               4  AB de Villiers   \n",
      "574               0    MC Henriques   \n",
      "575               4       DA Warner   \n",
      "576               0     BCJ Cutting   \n",
      "\n",
      "                                                venue          umpire1  \\\n",
      "0                               M Chinnaswamy Stadium        Asad Rauf   \n",
      "1          Punjab Cricket Association Stadium, Mohali        MR Benson   \n",
      "2                                    Feroz Shah Kotla        Aleem Dar   \n",
      "3                                    Wankhede Stadium         SJ Davis   \n",
      "4                                        Eden Gardens        BF Bowden   \n",
      "..                                                ...              ...   \n",
      "572  Shaheed Veer Narayan Singh International Stadium   A Nand Kishore   \n",
      "573                             M Chinnaswamy Stadium     AK Chaudhary   \n",
      "574                                  Feroz Shah Kotla        M Erasmus   \n",
      "575                                  Feroz Shah Kotla        M Erasmus   \n",
      "576                             M Chinnaswamy Stadium  HDPK Dharmasena   \n",
      "\n",
      "             umpire2  umpire3  \n",
      "0        RE Koertzen      NaN  \n",
      "1         SL Shastri      NaN  \n",
      "2     GA Pratapkumar      NaN  \n",
      "3          DJ Harper      NaN  \n",
      "4        K Hariharan      NaN  \n",
      "..               ...      ...  \n",
      "572     BNJ Oxenford      NaN  \n",
      "573  HDPK Dharmasena      NaN  \n",
      "574    C Shamshuddin      NaN  \n",
      "575        CK Nandan      NaN  \n",
      "576     BNJ Oxenford      NaN  \n",
      "\n",
      "[577 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/12345k/IPL-Dataset/master/IPL/data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d49e71c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crop     year   area     msp  yields\n",
      "0            rice  2014-15  15759    1360  378216\n",
      "1            rice  2015-16  15987    1414  383688\n",
      "2            rice  2016-17  15747    1470  377928\n",
      "3            rice  2017-18  15958    1550  382992\n",
      "4            rice  2018-19  15848    1750  380352\n",
      "5           maize  2014-15   1199    1310   29975\n",
      "6           maize  2015-16   1227    1325   30675\n",
      "7           maize  2016-17   1325    1365   33125\n",
      "8           maize  2017-18   1369    1425   34225\n",
      "9           maize  2018-19    951    1700   23775\n",
      "10      greengram  2014-15     45    4600     225\n",
      "11      greengram  2015-16     40    4850     200\n",
      "12      greengram  2016-17     51    5225     255\n",
      "13      greengram  2017-18     40    5575     200\n",
      "14      greengram  2018-19     38    6975     190\n",
      "15        redgram  2014-15     27    3175     168\n",
      "16       red gram  2015-16     12    3500      72\n",
      "17       red gram  2016-17     16    4000      80\n",
      "18       red gram  2017-18     33    4400     165\n",
      "19       red gram  2018-19     30    4600     150\n",
      "20         cotton  2014-15    183    3750    1098\n",
      "21         cotton  2015-16    176    3800    1056\n",
      "22         cotton  2016-17    135    3860     810\n",
      "23         cotton  2017-18    157    4020     942\n",
      "24         cotton  2018-19     79    5150     474\n",
      "25       turmeric  2014-15      3       2      30\n",
      "26       turmeric  2015-16      7       2      70\n",
      "27       turmeric  2016-17      2       2      20\n",
      "28       turmeric  2017-18      3       2      30\n",
      "29       turmeric  2018-19      6       2      60\n",
      "30      sugarcane  2014-15   2627     220  525400\n",
      "31      sugarcane  2015-16   1863     230  372600\n",
      "32      sugarcane  2016-17   1711     230  342200\n",
      "33      sugarcane  2017-18   1448     255  289600\n",
      "34      sugarcane  2018-19   1266     275  253200\n",
      "35          mango  2014-15   3408   10000   51015\n",
      "36          mango  2015-16   2527   10100   37905\n",
      "37          mango  2016-17   2092   11000   31380\n",
      "38          mango  2017-18   1829   11500   87435\n",
      "39          mango  2018-19   1627   13000   24405\n",
      "40     cashew nut  2014-15    284   10000     568\n",
      "41     cashew nut  2015-16    254   11000     508\n",
      "42     cashew nut  2016-17    223   12000     446\n",
      "43     cashew nut  2017-18    226   13000     452\n",
      "44     cashew nut  2018-19    189   19000     378\n",
      "45         banana  2014-15    116    6000   18560\n",
      "46         banana  2015-16    235    7000   43600\n",
      "47         banana  2016-17     76    9000   12160\n",
      "48         banana  2017-18     70   10000   11200\n",
      "49         banana  2018-19     36   15000    5760\n",
      "50          guava  2014-15    176    9000    1760\n",
      "51          guava  2015-16    242    9500    2420\n",
      "52          guava  2016-17    302    9600    3020\n",
      "53          guava  2017-18    345    9700    3450\n",
      "54          guava  2018-19    363   10000    3630\n",
      "55          lemon  2014-15     49   15000     245\n",
      "56          lemon  2015-16     54   15500     270\n",
      "57          lemon  2016-17     67   16000     335\n",
      "58          lemon  2017-18     95   17000     475\n",
      "59          lemon  2018-19     95   17500     475\n",
      "60        coconut  2014-15    188    1450   56400\n",
      "61        coconut  2015-16    169    1500   50700\n",
      "62        coconut  2016-17    137    1600   41100\n",
      "63        coconut  2017-18    152    1760   45600\n",
      "64        coconut  2018-19    155    2030   46100\n",
      "65         sapota  2014-15     21    6000     840\n",
      "66         sapota  2015-16     79    5000    3160\n",
      "67         sapota  2016-17     68    5500    2720\n",
      "68         sapota  2017-18     74    6200    2960\n",
      "69         sapota  2018-19     70    6500    2800\n",
      "70        palmoil  2014-15   1487   30000  386620\n",
      "71        palmoil  2015-16   1792   35000  465920\n",
      "72        palmoil  2016-17   1866   36000  485160\n",
      "73        palmoil  2017-18   1915   38000  497900\n",
      "74        palmoil  2018-19   1955   40000  508300\n",
      "75      eukalptus  2014-15   2003    8000  460690\n",
      "76      eukalptus  2015-16   2548    8500  586040\n",
      "77      eukalytus  2016-17   2585    9000  594550\n",
      "78      eukalytus  2017-18   2664    9500  612720\n",
      "79      eukalytus  2018-19   2668   10000  613640\n",
      "80        malbari  2014-15      5   90000    2250\n",
      "81        malbari  2015-16      5   80000    2850\n",
      "82        malbari  2016-17     19   60000    8550\n",
      "83        malbari  2017-18     17   85000    7650\n",
      "84        malbari  2018-19     19   90000    8559\n",
      "85     chedu vepa  2014-15     15   56000    3750\n",
      "86     chedu vepa  2015-16     15   59000    3750\n",
      "87     chedu vepa  2016-17     15   65000    3750\n",
      "88     chedu vepa  2017-18     19   67000    4750\n",
      "89     chedu vepa  2018-19     19   75000    4750\n",
      "90          tekku  2014-15     25  150000      10\n",
      "91          tekku  2015-16     32  160000      10\n",
      "92          tekku  2016-17     34  175000      10\n",
      "93          tekku  2017-18     40  189000      10\n",
      "94          tekku  2018-19     40  190000      10\n",
      "95  errachandanam  2014-15      5  150000      10\n",
      "96  errachandanam  2015-16      5  160000      10\n",
      "97  errachandanam  2016-17      9  190000      10\n",
      "98  errachandanam  2017-18     10  195000      10\n",
      "99  errachandanam  2018-19     12  209000      10\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/crops.csv\")\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283aeba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   crop     year   area   msp  yields\n",
      "0  rice  2014-15  15759  1360  378216\n",
      "1  rice  2015-16  15987  1414  383688\n",
      "2  rice  2016-17  15747  1470  377928\n",
      "3  rice  2017-18  15958  1550  382992\n",
      "4  rice  2018-19  15848  1750  380352\n",
      "         crop     year   area   msp  yields\n",
      "0        rice  2014-15  15759  1360  378216\n",
      "1        rice  2015-16  15987  1414  383688\n",
      "2        rice  2016-17  15747  1470  377928\n",
      "3        rice  2017-18  15958  1550  382992\n",
      "4        rice  2018-19  15848  1750  380352\n",
      "5       maize  2014-15   1199  1310   29975\n",
      "6       maize  2015-16   1227  1325   30675\n",
      "7       maize  2016-17   1325  1365   33125\n",
      "8       maize  2017-18   1369  1425   34225\n",
      "9       maize  2018-19    951  1700   23775\n",
      "10  greengram  2014-15     45  4600     225\n",
      "11  greengram  2015-16     40  4850     200\n",
      "12  greengram  2016-17     51  5225     255\n",
      "13  greengram  2017-18     40  5575     200\n",
      "14  greengram  2018-19     38  6975     190\n",
      "             crop     year  area     msp  yields\n",
      "95  errachandanam  2014-15     5  150000      10\n",
      "96  errachandanam  2015-16     5  160000      10\n",
      "97  errachandanam  2016-17     9  190000      10\n",
      "98  errachandanam  2017-18    10  195000      10\n",
      "99  errachandanam  2018-19    12  209000      10\n",
      "             crop     year  area     msp  yields\n",
      "85     chedu vepa  2014-15    15   56000    3750\n",
      "86     chedu vepa  2015-16    15   59000    3750\n",
      "87     chedu vepa  2016-17    15   65000    3750\n",
      "88     chedu vepa  2017-18    19   67000    4750\n",
      "89     chedu vepa  2018-19    19   75000    4750\n",
      "90          tekku  2014-15    25  150000      10\n",
      "91          tekku  2015-16    32  160000      10\n",
      "92          tekku  2016-17    34  175000      10\n",
      "93          tekku  2017-18    40  189000      10\n",
      "94          tekku  2018-19    40  190000      10\n",
      "95  errachandanam  2014-15     5  150000      10\n",
      "96  errachandanam  2015-16     5  160000      10\n",
      "97  errachandanam  2016-17     9  190000      10\n",
      "98  errachandanam  2017-18    10  195000      10\n",
      "99  errachandanam  2018-19    12  209000      10\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.head(15))\n",
    "print(df.tail())\n",
    "print(df.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0ee2fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crop\n",
      "0            rice\n",
      "1            rice\n",
      "2            rice\n",
      "3            rice\n",
      "4            rice\n",
      "5           maize\n",
      "6           maize\n",
      "7           maize\n",
      "8           maize\n",
      "9           maize\n",
      "10      greengram\n",
      "11      greengram\n",
      "12      greengram\n",
      "13      greengram\n",
      "14      greengram\n",
      "15        redgram\n",
      "16       red gram\n",
      "17       red gram\n",
      "18       red gram\n",
      "19       red gram\n",
      "20         cotton\n",
      "21         cotton\n",
      "22         cotton\n",
      "23         cotton\n",
      "24         cotton\n",
      "25       turmeric\n",
      "26       turmeric\n",
      "27       turmeric\n",
      "28       turmeric\n",
      "29       turmeric\n",
      "30      sugarcane\n",
      "31      sugarcane\n",
      "32      sugarcane\n",
      "33      sugarcane\n",
      "34      sugarcane\n",
      "35          mango\n",
      "36          mango\n",
      "37          mango\n",
      "38          mango\n",
      "39          mango\n",
      "40     cashew nut\n",
      "41     cashew nut\n",
      "42     cashew nut\n",
      "43     cashew nut\n",
      "44     cashew nut\n",
      "45         banana\n",
      "46         banana\n",
      "47         banana\n",
      "48         banana\n",
      "49         banana\n",
      "50          guava\n",
      "51          guava\n",
      "52          guava\n",
      "53          guava\n",
      "54          guava\n",
      "55          lemon\n",
      "56          lemon\n",
      "57          lemon\n",
      "58          lemon\n",
      "59          lemon\n",
      "60        coconut\n",
      "61        coconut\n",
      "62        coconut\n",
      "63        coconut\n",
      "64        coconut\n",
      "65         sapota\n",
      "66         sapota\n",
      "67         sapota\n",
      "68         sapota\n",
      "69         sapota\n",
      "70        palmoil\n",
      "71        palmoil\n",
      "72        palmoil\n",
      "73        palmoil\n",
      "74        palmoil\n",
      "75      eukalptus\n",
      "76      eukalptus\n",
      "77      eukalytus\n",
      "78      eukalytus\n",
      "79      eukalytus\n",
      "80        malbari\n",
      "81        malbari\n",
      "82        malbari\n",
      "83        malbari\n",
      "84        malbari\n",
      "85     chedu vepa\n",
      "86     chedu vepa\n",
      "87     chedu vepa\n",
      "88     chedu vepa\n",
      "89     chedu vepa\n",
      "90          tekku\n",
      "91          tekku\n",
      "92          tekku\n",
      "93          tekku\n",
      "94          tekku\n",
      "95  errachandanam\n",
      "96  errachandanam\n",
      "97  errachandanam\n",
      "98  errachandanam\n",
      "99  errachandanam\n",
      "   crop\n",
      "0  rice\n",
      "1  rice\n",
      "2  rice\n",
      "3  rice\n",
      "4  rice\n",
      "         crop   area   msp\n",
      "0        rice  15759  1360\n",
      "1        rice  15987  1414\n",
      "2        rice  15747  1470\n",
      "3        rice  15958  1550\n",
      "4        rice  15848  1750\n",
      "5       maize   1199  1310\n",
      "6       maize   1227  1325\n",
      "7       maize   1325  1365\n",
      "8       maize   1369  1425\n",
      "9       maize    951  1700\n",
      "10  greengram     45  4600\n",
      "11  greengram     40  4850\n",
      "12  greengram     51  5225\n",
      "13  greengram     40  5575\n",
      "14  greengram     38  6975\n",
      "             crop   area     msp\n",
      "0            rice  15759    1360\n",
      "1            rice  15987    1414\n",
      "2            rice  15747    1470\n",
      "3            rice  15958    1550\n",
      "4            rice  15848    1750\n",
      "5           maize   1199    1310\n",
      "6           maize   1227    1325\n",
      "7           maize   1325    1365\n",
      "8           maize   1369    1425\n",
      "9           maize    951    1700\n",
      "10      greengram     45    4600\n",
      "11      greengram     40    4850\n",
      "12      greengram     51    5225\n",
      "13      greengram     40    5575\n",
      "14      greengram     38    6975\n",
      "15        redgram     27    3175\n",
      "16       red gram     12    3500\n",
      "17       red gram     16    4000\n",
      "18       red gram     33    4400\n",
      "19       red gram     30    4600\n",
      "20         cotton    183    3750\n",
      "21         cotton    176    3800\n",
      "22         cotton    135    3860\n",
      "23         cotton    157    4020\n",
      "24         cotton     79    5150\n",
      "25       turmeric      3       2\n",
      "26       turmeric      7       2\n",
      "27       turmeric      2       2\n",
      "28       turmeric      3       2\n",
      "29       turmeric      6       2\n",
      "30      sugarcane   2627     220\n",
      "31      sugarcane   1863     230\n",
      "32      sugarcane   1711     230\n",
      "33      sugarcane   1448     255\n",
      "34      sugarcane   1266     275\n",
      "35          mango   3408   10000\n",
      "36          mango   2527   10100\n",
      "37          mango   2092   11000\n",
      "38          mango   1829   11500\n",
      "39          mango   1627   13000\n",
      "40     cashew nut    284   10000\n",
      "41     cashew nut    254   11000\n",
      "42     cashew nut    223   12000\n",
      "43     cashew nut    226   13000\n",
      "44     cashew nut    189   19000\n",
      "45         banana    116    6000\n",
      "46         banana    235    7000\n",
      "47         banana     76    9000\n",
      "48         banana     70   10000\n",
      "49         banana     36   15000\n",
      "50          guava    176    9000\n",
      "51          guava    242    9500\n",
      "52          guava    302    9600\n",
      "53          guava    345    9700\n",
      "54          guava    363   10000\n",
      "55          lemon     49   15000\n",
      "56          lemon     54   15500\n",
      "57          lemon     67   16000\n",
      "58          lemon     95   17000\n",
      "59          lemon     95   17500\n",
      "60        coconut    188    1450\n",
      "61        coconut    169    1500\n",
      "62        coconut    137    1600\n",
      "63        coconut    152    1760\n",
      "64        coconut    155    2030\n",
      "65         sapota     21    6000\n",
      "66         sapota     79    5000\n",
      "67         sapota     68    5500\n",
      "68         sapota     74    6200\n",
      "69         sapota     70    6500\n",
      "70        palmoil   1487   30000\n",
      "71        palmoil   1792   35000\n",
      "72        palmoil   1866   36000\n",
      "73        palmoil   1915   38000\n",
      "74        palmoil   1955   40000\n",
      "75      eukalptus   2003    8000\n",
      "76      eukalptus   2548    8500\n",
      "77      eukalytus   2585    9000\n",
      "78      eukalytus   2664    9500\n",
      "79      eukalytus   2668   10000\n",
      "80        malbari      5   90000\n",
      "81        malbari      5   80000\n",
      "82        malbari     19   60000\n",
      "83        malbari     17   85000\n",
      "84        malbari     19   90000\n",
      "85     chedu vepa     15   56000\n",
      "86     chedu vepa     15   59000\n",
      "87     chedu vepa     15   65000\n",
      "88     chedu vepa     19   67000\n",
      "89     chedu vepa     19   75000\n",
      "90          tekku     25  150000\n",
      "91          tekku     32  160000\n",
      "92          tekku     34  175000\n",
      "93          tekku     40  189000\n",
      "94          tekku     40  190000\n",
      "95  errachandanam      5  150000\n",
      "96  errachandanam      5  160000\n",
      "97  errachandanam      9  190000\n",
      "98  errachandanam     10  195000\n",
      "99  errachandanam     12  209000\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"crop\"]])\n",
    "print(df[[\"crop\"]].head())\n",
    "print(df[[\"crop\",\"area\",\"msp\"]].head(15)) #Gives 3 columns - crop,area,msp\n",
    "print(df[[\"crop\",\"area\",\"msp\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b4d1f",
   "metadata": {},
   "source": [
    "# Pandas Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699df2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78357995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crop     year   area     msp  yields\n",
      "0            rice  2014-15  15759    1360  378216\n",
      "1            rice  2015-16  15987    1414  383688\n",
      "2            rice  2016-17  15747    1470  377928\n",
      "3            rice  2017-18  15958    1550  382992\n",
      "4            rice  2018-19  15848    1750  380352\n",
      "..            ...      ...    ...     ...     ...\n",
      "95  errachandanam  2014-15      5  150000      10\n",
      "96  errachandanam  2015-16      5  160000      10\n",
      "97  errachandanam  2016-17      9  190000      10\n",
      "98  errachandanam  2017-18     10  195000      10\n",
      "99  errachandanam  2018-19     12  209000      10\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/crops.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341b9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop      object\n",
      "year      object\n",
      "area       int64\n",
      "msp        int64\n",
      "yields     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes) #gives data types to entire file which is having 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580688e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"area\"].dtypes) # gives data type of specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71bfa796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['crop', 'year', 'area', 'msp', 'yields'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) #gives the column names as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e513990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RangeIndex(start=0, stop=100, step=1), Index(['crop', 'year', 'area', 'msp', 'yields'], dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "print(df.axes) #gives the rows and columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f0e957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df.ndim) #gives no of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e9d841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(df.size) #Total tuples in the file i.e 100*5 = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55695d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) #gives the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca861549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rice' '2014-15' 15759 1360 378216]\n",
      " ['rice' '2015-16' 15987 1414 383688]\n",
      " ['rice' '2016-17' 15747 1470 377928]\n",
      " ['rice' '2017-18' 15958 1550 382992]\n",
      " ['rice' '2018-19' 15848 1750 380352]\n",
      " ['maize' '2014-15' 1199 1310 29975]\n",
      " ['maize' '2015-16' 1227 1325 30675]\n",
      " ['maize' '2016-17' 1325 1365 33125]\n",
      " ['maize' '2017-18' 1369 1425 34225]\n",
      " ['maize' '2018-19' 951 1700 23775]\n",
      " ['greengram' '2014-15' 45 4600 225]\n",
      " ['greengram' '2015-16' 40 4850 200]\n",
      " ['greengram' '2016-17' 51 5225 255]\n",
      " ['greengram' '2017-18' 40 5575 200]\n",
      " ['greengram' '2018-19' 38 6975 190]\n",
      " ['redgram' '2014-15' 27 3175 168]\n",
      " ['red gram' '2015-16' 12 3500 72]\n",
      " ['red gram' '2016-17' 16 4000 80]\n",
      " ['red gram' '2017-18' 33 4400 165]\n",
      " ['red gram' '2018-19' 30 4600 150]\n",
      " ['cotton' '2014-15' 183 3750 1098]\n",
      " ['cotton' '2015-16' 176 3800 1056]\n",
      " ['cotton' '2016-17' 135 3860 810]\n",
      " ['cotton' '2017-18' 157 4020 942]\n",
      " ['cotton' '2018-19' 79 5150 474]\n",
      " ['turmeric' '2014-15' 3 2 30]\n",
      " ['turmeric' '2015-16' 7 2 70]\n",
      " ['turmeric' '2016-17' 2 2 20]\n",
      " ['turmeric' '2017-18' 3 2 30]\n",
      " ['turmeric' '2018-19' 6 2 60]\n",
      " ['sugarcane' '2014-15' 2627 220 525400]\n",
      " ['sugarcane' '2015-16' 1863 230 372600]\n",
      " ['sugarcane' '2016-17' 1711 230 342200]\n",
      " ['sugarcane' '2017-18' 1448 255 289600]\n",
      " ['sugarcane' '2018-19' 1266 275 253200]\n",
      " ['mango' '2014-15' 3408 10000 51015]\n",
      " ['mango' '2015-16' 2527 10100 37905]\n",
      " ['mango' '2016-17' 2092 11000 31380]\n",
      " ['mango' '2017-18' 1829 11500 87435]\n",
      " ['mango' '2018-19' 1627 13000 24405]\n",
      " ['cashew nut' '2014-15' 284 10000 568]\n",
      " ['cashew nut' '2015-16' 254 11000 508]\n",
      " ['cashew nut' '2016-17' 223 12000 446]\n",
      " ['cashew nut' '2017-18' 226 13000 452]\n",
      " ['cashew nut' '2018-19' 189 19000 378]\n",
      " ['banana' '2014-15' 116 6000 18560]\n",
      " ['banana' '2015-16' 235 7000 43600]\n",
      " ['banana' '2016-17' 76 9000 12160]\n",
      " ['banana' '2017-18' 70 10000 11200]\n",
      " ['banana' '2018-19' 36 15000 5760]\n",
      " ['guava' '2014-15' 176 9000 1760]\n",
      " ['guava' '2015-16' 242 9500 2420]\n",
      " ['guava' '2016-17' 302 9600 3020]\n",
      " ['guava' '2017-18' 345 9700 3450]\n",
      " ['guava' '2018-19' 363 10000 3630]\n",
      " ['lemon' '2014-15' 49 15000 245]\n",
      " ['lemon' '2015-16' 54 15500 270]\n",
      " ['lemon' '2016-17' 67 16000 335]\n",
      " ['lemon' '2017-18' 95 17000 475]\n",
      " ['lemon' '2018-19' 95 17500 475]\n",
      " ['coconut' '2014-15' 188 1450 56400]\n",
      " ['coconut' '2015-16' 169 1500 50700]\n",
      " ['coconut' '2016-17' 137 1600 41100]\n",
      " ['coconut' '2017-18' 152 1760 45600]\n",
      " ['coconut' '2018-19' 155 2030 46100]\n",
      " ['sapota' '2014-15' 21 6000 840]\n",
      " ['sapota' '2015-16' 79 5000 3160]\n",
      " ['sapota' '2016-17' 68 5500 2720]\n",
      " ['sapota' '2017-18' 74 6200 2960]\n",
      " ['sapota' '2018-19' 70 6500 2800]\n",
      " ['palmoil' '2014-15' 1487 30000 386620]\n",
      " ['palmoil' '2015-16' 1792 35000 465920]\n",
      " ['palmoil' '2016-17' 1866 36000 485160]\n",
      " ['palmoil' '2017-18' 1915 38000 497900]\n",
      " ['palmoil' '2018-19' 1955 40000 508300]\n",
      " ['eukalptus' '2014-15' 2003 8000 460690]\n",
      " ['eukalptus' '2015-16' 2548 8500 586040]\n",
      " ['eukalytus' '2016-17' 2585 9000 594550]\n",
      " ['eukalytus' '2017-18' 2664 9500 612720]\n",
      " ['eukalytus' '2018-19' 2668 10000 613640]\n",
      " ['malbari' '2014-15' 5 90000 2250]\n",
      " ['malbari' '2015-16' 5 80000 2850]\n",
      " ['malbari' '2016-17' 19 60000 8550]\n",
      " ['malbari' '2017-18' 17 85000 7650]\n",
      " ['malbari' '2018-19' 19 90000 8559]\n",
      " ['chedu vepa' '2014-15' 15 56000 3750]\n",
      " ['chedu vepa' '2015-16' 15 59000 3750]\n",
      " ['chedu vepa' '2016-17' 15 65000 3750]\n",
      " ['chedu vepa' '2017-18' 19 67000 4750]\n",
      " ['chedu vepa' '2018-19' 19 75000 4750]\n",
      " ['tekku' '2014-15' 25 150000 10]\n",
      " ['tekku' '2015-16' 32 160000 10]\n",
      " ['tekku' '2016-17' 34 175000 10]\n",
      " ['tekku' '2017-18' 40 189000 10]\n",
      " ['tekku' '2018-19' 40 190000 10]\n",
      " ['errachandanam' '2014-15' 5 150000 10]\n",
      " ['errachandanam' '2015-16' 5 160000 10]\n",
      " ['errachandanam' '2016-17' 9 190000 10]\n",
      " ['errachandanam' '2017-18' 10 195000 10]\n",
      " ['errachandanam' '2018-19' 12 209000 10]]\n"
     ]
    }
   ],
   "source": [
    "print(df.values) #Numpy representation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73232c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of              crop     year   area     msp  yields\n",
      "0            rice  2014-15  15759    1360  378216\n",
      "1            rice  2015-16  15987    1414  383688\n",
      "2            rice  2016-17  15747    1470  377928\n",
      "3            rice  2017-18  15958    1550  382992\n",
      "4            rice  2018-19  15848    1750  380352\n",
      "..            ...      ...    ...     ...     ...\n",
      "95  errachandanam  2014-15      5  150000      10\n",
      "96  errachandanam  2015-16      5  160000      10\n",
      "97  errachandanam  2016-17      9  190000      10\n",
      "98  errachandanam  2017-18     10  195000      10\n",
      "99  errachandanam  2018-19     12  209000      10\n",
      "\n",
      "[100 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.info) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76566811",
   "metadata": {},
   "source": [
    "# Pandas Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7e558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6c2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/crops.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b7d423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               area            msp         yields\n",
      "count    100.000000     100.000000     100.000000\n",
      "mean    1333.040000   31363.090000   97007.270000\n",
      "std     3454.998174   53527.125655  181610.087946\n",
      "min        2.000000       2.000000      10.000000\n",
      "25%       29.250000    2888.750000     252.500000\n",
      "50%      125.500000    9000.000000    3305.000000\n",
      "75%     1336.000000   21750.000000   45725.000000\n",
      "max    15987.000000  209000.000000  613640.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe ()) #Gives the description of crops data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5075ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop      turmeric\n",
      "year       2018-19\n",
      "area         15987\n",
      "msp         209000\n",
      "yields      613640\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.max()) #Gives the maximum value of entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167aba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15987\n"
     ]
    }
   ],
   "source": [
    "print(df[\"area\"].max()) #Gives the maximum value of particular value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f33b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df[\"area\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06df654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area       1333.04\n",
      "msp       31363.09\n",
      "yields    97007.27\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8892\\2807316344.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(df.mean())\n"
     ]
    }
   ],
   "source": [
    "print(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a9e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333.04\n"
     ]
    }
   ],
   "source": [
    "print(df[\"area\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f967c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area        3454.998174\n",
      "msp        53527.125655\n",
      "yields    181610.087946\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_8892\\1717847374.py:1: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(df.std()) #standard deviation\n"
     ]
    }
   ],
   "source": [
    "print(df.std()) #standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3492d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rice' 'maize' 'greengram' 'redgram' 'red gram' 'cotton' 'turmeric'\n",
      " 'sugarcane' 'mango' 'cashew nut' 'banana' 'guava' 'lemon' 'coconut'\n",
      " 'sapota' 'palmoil' 'eukalptus' 'eukalytus' 'malbari' 'chedu vepa' 'tekku'\n",
      " 'errachandanam']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"crop\"].unique()) #get unique values of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6006f432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15759 15987 15747 15958 15848  1199  1227  1325  1369   951    45    40\n",
      "    51    38    27    12    16    33    30   183   176   135   157    79\n",
      "     3     7     2     6  2627  1863  1711  1448  1266  3408  2527  2092\n",
      "  1829  1627   284   254   223   226   189   116   235    76    70    36\n",
      "   242   302   345   363    49    54    67    95   188   169   137   152\n",
      "   155    21    68    74  1487  1792  1866  1915  1955  2003  2548  2585\n",
      "  2664  2668     5    19    17    15    25    32    34     9    10]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"area\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01b8755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rice' 'maize' 'greengram' 'redgram' 'cotton' 'turmeric' 'sugarcane'\n",
      " 'mango' 'cashew nut' 'banana' 'guava' 'lemon' 'coconut' 'sapota'\n",
      " 'palmoil' 'eukalptus' 'malbari' 'chedu vepa' 'tekku' 'errachandanam']\n",
      "         crop     year   area   msp  yields\n",
      "0        rice  2014-15  15759  1360  378216\n",
      "1        rice  2015-16  15987  1414  383688\n",
      "2        rice  2016-17  15747  1470  377928\n",
      "3        rice  2017-18  15958  1550  382992\n",
      "4        rice  2018-19  15848  1750  380352\n",
      "5       maize  2014-15   1199  1310   29975\n",
      "6       maize  2015-16   1227  1325   30675\n",
      "7       maize  2016-17   1325  1365   33125\n",
      "8       maize  2017-18   1369  1425   34225\n",
      "9       maize  2018-19    951  1700   23775\n",
      "10  greengram  2014-15     45  4600     225\n",
      "11  greengram  2015-16     40  4850     200\n",
      "12  greengram  2016-17     51  5225     255\n",
      "13  greengram  2017-18     40  5575     200\n",
      "14  greengram  2018-19     38  6975     190\n",
      "15    redgram  2014-15     27  3175     168\n",
      "16    redgram  2015-16     12  3500      72\n",
      "17    redgram  2016-17     16  4000      80\n",
      "18    redgram  2017-18     33  4400     165\n",
      "19    redgram  2018-19     30  4600     150\n",
      "20     cotton  2014-15    183  3750    1098\n",
      "21     cotton  2015-16    176  3800    1056\n",
      "22     cotton  2016-17    135  3860     810\n",
      "23     cotton  2017-18    157  4020     942\n",
      "24     cotton  2018-19     79  5150     474\n"
     ]
    }
   ],
   "source": [
    "df1=df\n",
    "df[\"crop\"]=df.crop.replace(\"red gram\",\"redgram\")\n",
    "df[\"crop\"]=df.crop.replace(\"eukalytus\",\"eukalptus\")\n",
    "print(df[\"crop\"].unique())\n",
    "print(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c8ed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              rice\n",
      "1              rice\n",
      "2              rice\n",
      "3              rice\n",
      "4              rice\n",
      "          ...      \n",
      "95    errachandanam\n",
      "96    errachandanam\n",
      "97    errachandanam\n",
      "98    errachandanam\n",
      "99    errachandanam\n",
      "Name: crop, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1=df[\"crop\"]\n",
    "df1=df.crop.replace(\"red gram\",\"redgram\")\n",
    "df1=df.crop.replace(\"eukalytus\",\"eukalptus\")\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86cf4f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          rice\n",
      "1          rice\n",
      "2          rice\n",
      "3          rice\n",
      "4          rice\n",
      "5         maize\n",
      "6         maize\n",
      "7         maize\n",
      "8         maize\n",
      "9         maize\n",
      "10    greengram\n",
      "11    greengram\n",
      "12    greengram\n",
      "13    greengram\n",
      "14    greengram\n",
      "15      redgram\n",
      "16      redgram\n",
      "17      redgram\n",
      "18      redgram\n",
      "19      redgram\n",
      "20       cotton\n",
      "21       cotton\n",
      "22       cotton\n",
      "23       cotton\n",
      "24       cotton\n",
      "25     turmeric\n",
      "26     turmeric\n",
      "27     turmeric\n",
      "28     turmeric\n",
      "29     turmeric\n",
      "Name: crop, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df1.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b3d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rice             5\n",
      "maize            5\n",
      "tekku            5\n",
      "chedu vepa       5\n",
      "malbari          5\n",
      "eukalptus        5\n",
      "palmoil          5\n",
      "sapota           5\n",
      "coconut          5\n",
      "lemon            5\n",
      "guava            5\n",
      "banana           5\n",
      "cashew nut       5\n",
      "mango            5\n",
      "sugarcane        5\n",
      "turmeric         5\n",
      "cotton           5\n",
      "redgram          5\n",
      "greengram        5\n",
      "errachandanam    5\n",
      "Name: crop, dtype: int64\n",
      "19      4\n",
      "5       4\n",
      "40      4\n",
      "15      3\n",
      "95      2\n",
      "       ..\n",
      "1711    1\n",
      "1863    1\n",
      "2627    1\n",
      "6       1\n",
      "10      1\n",
      "Name: area, Length: 83, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"crop\"].value_counts()) #Get the unique category counts\n",
    "print(df[\"area\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195bb530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             crop     year  area     msp  yields\n",
      "89     chedu vepa  2018-19    19   75000    4750\n",
      "31      sugarcane  2015-16  1863     230  372600\n",
      "70        palmoil  2014-15  1487   30000  386620\n",
      "61        coconut  2015-16   169    1500   50700\n",
      "22         cotton  2016-17   135    3860     810\n",
      "47         banana  2016-17    76    9000   12160\n",
      "45         banana  2014-15   116    6000   18560\n",
      "50          guava  2014-15   176    9000    1760\n",
      "80        malbari  2014-15     5   90000    2250\n",
      "40     cashew nut  2014-15   284   10000     568\n",
      "98  errachandanam  2017-18    10  195000      10\n",
      "79      eukalptus  2018-19  2668   10000  613640\n",
      "12      greengram  2016-17    51    5225     255\n",
      "5           maize  2014-15  1199    1310   29975\n",
      "51          guava  2015-16   242    9500    2420\n"
     ]
    }
   ],
   "source": [
    "df1=df.sample(n=15)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e1b7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         crop  area  yields\n",
      "51      guava   242    2420\n",
      "52      guava   302    3020\n",
      "53      guava   345    3450\n",
      "54      guava   363    3630\n",
      "55      lemon    49     245\n",
      "56      lemon    54     270\n",
      "57      lemon    67     335\n",
      "58      lemon    95     475\n",
      "59      lemon    95     475\n",
      "60    coconut   188   56400\n",
      "61    coconut   169   50700\n",
      "62    coconut   137   41100\n",
      "63    coconut   152   45600\n",
      "64    coconut   155   46100\n",
      "65     sapota    21     840\n",
      "66     sapota    79    3160\n",
      "67     sapota    68    2720\n",
      "68     sapota    74    2960\n",
      "69     sapota    70    2800\n",
      "70    palmoil  1487  386620\n",
      "71    palmoil  1792  465920\n",
      "72    palmoil  1866  485160\n",
      "73    palmoil  1915  497900\n",
      "74    palmoil  1955  508300\n",
      "75  eukalptus  2003  460690\n"
     ]
    }
   ],
   "source": [
    "df1=df.loc[51:75,[\"crop\",\"area\",\"yields\"]] #.loc[from:to,[\"c1\",\"c2\",\"c3\"]] #.loc[rows,columns]\n",
    "print(df1) #Gives records from 5 - 15 for 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce19b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       crop     year  area    msp  yields\n",
      "51    guava  2015-16   242   9500    2420\n",
      "52    guava  2016-17   302   9600    3020\n",
      "53    guava  2017-18   345   9700    3450\n",
      "54    guava  2018-19   363  10000    3630\n",
      "55    lemon  2014-15    49  15000     245\n",
      "56    lemon  2015-16    54  15500     270\n",
      "57    lemon  2016-17    67  16000     335\n",
      "58    lemon  2017-18    95  17000     475\n",
      "59    lemon  2018-19    95  17500     475\n",
      "60  coconut  2014-15   188   1450   56400\n",
      "61  coconut  2015-16   169   1500   50700\n",
      "62  coconut  2016-17   137   1600   41100\n",
      "63  coconut  2017-18   152   1760   45600\n",
      "64  coconut  2018-19   155   2030   46100\n",
      "65   sapota  2014-15    21   6000     840\n",
      "66   sapota  2015-16    79   5000    3160\n",
      "67   sapota  2016-17    68   5500    2720\n",
      "68   sapota  2017-18    74   6200    2960\n",
      "69   sapota  2018-19    70   6500    2800\n",
      "             crop     year  area\n",
      "84        malbari  2018-19    19\n",
      "85     chedu vepa  2014-15    15\n",
      "86     chedu vepa  2015-16    15\n",
      "87     chedu vepa  2016-17    15\n",
      "88     chedu vepa  2017-18    19\n",
      "89     chedu vepa  2018-19    19\n",
      "90          tekku  2014-15    25\n",
      "91          tekku  2015-16    32\n",
      "92          tekku  2016-17    34\n",
      "93          tekku  2017-18    40\n",
      "94          tekku  2018-19    40\n",
      "95  errachandanam  2014-15     5\n",
      "96  errachandanam  2015-16     5\n",
      "97  errachandanam  2016-17     9\n",
      "98  errachandanam  2017-18    10\n",
      "99  errachandanam  2018-19    12\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[51:69])\n",
    "print(df.loc[84:,[\"crop\",\"year\",\"area\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7a300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year  area  yields\n",
      "10  2014-15    45     225\n",
      "11  2015-16    40     200\n",
      "12  2016-17    51     255\n",
      "13  2017-18    40     200\n",
      "14  2018-19    38     190\n",
      "15  2014-15    27     168\n",
      "16  2015-16    12      72\n",
      "17  2016-17    16      80\n",
      "18  2017-18    33     165\n",
      "19  2018-19    30     150\n",
      "       year  area   msp\n",
      "10  2014-15    45  4600\n",
      "11  2015-16    40  4850\n",
      "12  2016-17    51  5225\n",
      "13  2017-18    40  5575\n",
      "14  2018-19    38  6975\n",
      "15  2014-15    27  3175\n",
      "16  2015-16    12  3500\n",
      "17  2016-17    16  4000\n",
      "18  2017-18    33  4400\n",
      "19  2018-19    30  4600\n",
      "             crop   area     msp\n",
      "0            rice  15759    1360\n",
      "1            rice  15987    1414\n",
      "2            rice  15747    1470\n",
      "3            rice  15958    1550\n",
      "4            rice  15848    1750\n",
      "..            ...    ...     ...\n",
      "95  errachandanam      5  150000\n",
      "96  errachandanam      5  160000\n",
      "97  errachandanam      9  190000\n",
      "98  errachandanam     10  195000\n",
      "99  errachandanam     12  209000\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "         crop     year  area   msp  yields\n",
      "10  greengram  2014-15    45  4600     225\n",
      "11  greengram  2015-16    40  4850     200\n",
      "12  greengram  2016-17    51  5225     255\n",
      "13  greengram  2017-18    40  5575     200\n",
      "14  greengram  2018-19    38  6975     190\n",
      "15    redgram  2014-15    27  3175     168\n",
      "16    redgram  2015-16    12  3500      72\n",
      "17    redgram  2016-17    16  4000      80\n",
      "18    redgram  2017-18    33  4400     165\n",
      "19    redgram  2018-19    30  4600     150\n",
      "         crop     year   area   msp  yields\n",
      "0        rice  2014-15  15759  1360  378216\n",
      "1        rice  2015-16  15987  1414  383688\n",
      "2        rice  2016-17  15747  1470  377928\n",
      "3        rice  2017-18  15958  1550  382992\n",
      "4        rice  2018-19  15848  1750  380352\n",
      "5       maize  2014-15   1199  1310   29975\n",
      "6       maize  2015-16   1227  1325   30675\n",
      "7       maize  2016-17   1325  1365   33125\n",
      "8       maize  2017-18   1369  1425   34225\n",
      "9       maize  2018-19    951  1700   23775\n",
      "10  greengram  2014-15     45  4600     225\n",
      "11  greengram  2015-16     40  4850     200\n",
      "12  greengram  2016-17     51  5225     255\n",
      "13  greengram  2017-18     40  5575     200\n",
      "14  greengram  2018-19     38  6975     190\n",
      "15    redgram  2014-15     27  3175     168\n",
      "16    redgram  2015-16     12  3500      72\n",
      "17    redgram  2016-17     16  4000      80\n",
      "18    redgram  2017-18     33  4400     165\n",
      "19    redgram  2018-19     30  4600     150\n",
      "0     378216\n",
      "1     383688\n",
      "2     377928\n",
      "3     382992\n",
      "4     380352\n",
      "       ...  \n",
      "95        10\n",
      "96        10\n",
      "97        10\n",
      "98        10\n",
      "99        10\n",
      "Name: yields, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[10:20,[1,2,4]]) #Gives the data based on the index number of column\n",
    "print(df.iloc[10:20,1:4]) #\n",
    "print(df.iloc[:,[0,2,3]])\n",
    "print(df.iloc[10:20])\n",
    "print(df.iloc[:20])\n",
    "print(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df86dc",
   "metadata": {},
   "source": [
    "# Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7ac09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722f76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36546714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 color     director_name  num_critic_for_reviews  duration  \\\n",
      "0                Color     James Cameron                   723.0     178.0   \n",
      "10               Color       Zack Snyder                   673.0     183.0   \n",
      "17               Color       Joss Whedon                   703.0     173.0   \n",
      "23               Color     Peter Jackson                   509.0     186.0   \n",
      "25               Color     Peter Jackson                   446.0     201.0   \n",
      "...                ...               ...                     ...       ...   \n",
      "4113             Color               NaN                    10.0     173.0   \n",
      "4238   Black and White     William Wyler                    97.0     172.0   \n",
      "4694             Color     Peter Jackson                   446.0     201.0   \n",
      "4708             Color  Michael Wadleigh                    53.0     215.0   \n",
      "4747   Black and White    Akira Kurosawa                   153.0     202.0   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes        actor_2_name  \\\n",
      "0                         0.0                   855.0    Joel David Moore   \n",
      "10                        0.0                  2000.0        Lauren Cohan   \n",
      "17                        0.0                 19000.0   Robert Downey Jr.   \n",
      "23                        0.0                   773.0          Adam Brown   \n",
      "25                        0.0                    84.0  Thomas Kretschmann   \n",
      "...                       ...                     ...                 ...   \n",
      "4113                      NaN                   476.0          Colm Feore   \n",
      "4238                    355.0                   188.0       Teresa Wright   \n",
      "4694                      0.0                    84.0  Thomas Kretschmann   \n",
      "4708                     14.0                   136.0        Jimi Hendrix   \n",
      "4747                      0.0                     4.0       Minoru Chiaki   \n",
      "\n",
      "      actor_1_facebook_likes        gross                           genres  \\\n",
      "0                     1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
      "10                   15000.0  330249062.0          Action|Adventure|Sci-Fi   \n",
      "17                   26000.0  623279547.0          Action|Adventure|Sci-Fi   \n",
      "23                    5000.0  258355354.0                Adventure|Fantasy   \n",
      "25                    6000.0  218051260.0   Action|Adventure|Drama|Romance   \n",
      "...                      ...          ...                              ...   \n",
      "4113                   723.0          NaN           Horror|Sci-Fi|Thriller   \n",
      "4238                   749.0   23650000.0                Drama|Romance|War   \n",
      "4694                  6000.0  218051260.0   Action|Adventure|Drama|Romance   \n",
      "4708                   262.0   13300000.0        Documentary|History|Music   \n",
      "4747                   304.0     269061.0           Action|Adventure|Drama   \n",
      "\n",
      "      ... num_user_for_reviews  language      country  content_rating  \\\n",
      "0     ...               3054.0   English          USA           PG-13   \n",
      "10    ...               3018.0   English          USA           PG-13   \n",
      "17    ...               1722.0   English          USA           PG-13   \n",
      "23    ...                951.0   English          USA           PG-13   \n",
      "25    ...               2618.0   English  New Zealand           PG-13   \n",
      "...   ...                  ...       ...          ...             ...   \n",
      "4113  ...                 33.0   English          USA             NaN   \n",
      "4238  ...                235.0   English          USA       Not Rated   \n",
      "4694  ...               2618.0   English  New Zealand           PG-13   \n",
      "4708  ...                 63.0   English          USA               R   \n",
      "4747  ...                596.0  Japanese        Japan         Unrated   \n",
      "\n",
      "           budget  title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "0     237000000.0      2009.0                  936.0        7.9          1.78   \n",
      "10    250000000.0      2016.0                 4000.0        6.9          2.35   \n",
      "17    220000000.0      2012.0                21000.0        8.1          1.85   \n",
      "23    225000000.0      2013.0                  972.0        7.9          2.35   \n",
      "25    207000000.0      2005.0                  919.0        7.2          2.35   \n",
      "...           ...         ...                    ...        ...           ...   \n",
      "4113          NaN         NaN                  539.0        5.0          1.78   \n",
      "4238    2100000.0      1946.0                  208.0        8.1          1.37   \n",
      "4694  207000000.0      2005.0                  918.0        7.2          2.35   \n",
      "4708     600000.0      1970.0                  227.0        8.1          2.20   \n",
      "4747    2000000.0      1954.0                    8.0        8.7          1.37   \n",
      "\n",
      "     movie_facebook_likes  \n",
      "0                   33000  \n",
      "10                 197000  \n",
      "17                 123000  \n",
      "23                  83000  \n",
      "25                      0  \n",
      "...                   ...  \n",
      "4113                  518  \n",
      "4238                    0  \n",
      "4694                    0  \n",
      "4708                    0  \n",
      "4747                11000  \n",
      "\n",
      "[102 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "dt=df[df[\"duration\"]>170] #Row filtering\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde2ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         director_name                           movie_title  duration\n",
      "0        James Cameron                               Avatar      178.0\n",
      "10         Zack Snyder   Batman v Superman: Dawn of Justice      183.0\n",
      "17         Joss Whedon                         The Avengers      173.0\n",
      "23       Peter Jackson  The Hobbit: The Desolation of Smaug      186.0\n",
      "25       Peter Jackson                            King Kong      201.0\n",
      "...                ...                                   ...       ...\n",
      "4113               NaN                 Creature                  173.0\n",
      "4238     William Wyler          The Best Years of Our Lives      172.0\n",
      "4694     Peter Jackson                            King Kong      201.0\n",
      "4708  Michael Wadleigh                            Woodstock      215.0\n",
      "4747    Akira Kurosawa                        Seven Samurai      202.0\n",
      "\n",
      "[102 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dt[[\"director_name\",\"movie_title\",\"duration\"]]) #Column filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662fae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director_name</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Cameron</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zack Snyder</td>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>King Kong</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Creature</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>William Wyler</td>\n",
       "      <td>The Best Years of Our Lives</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>King Kong</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>Michael Wadleigh</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>Akira Kurosawa</td>\n",
       "      <td>Seven Samurai</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         director_name                           movie_title  duration\n",
       "0        James Cameron                               Avatar      178.0\n",
       "10         Zack Snyder   Batman v Superman: Dawn of Justice      183.0\n",
       "17         Joss Whedon                         The Avengers      173.0\n",
       "23       Peter Jackson  The Hobbit: The Desolation of Smaug      186.0\n",
       "25       Peter Jackson                            King Kong      201.0\n",
       "...                ...                                   ...       ...\n",
       "4113               NaN                 Creature                  173.0\n",
       "4238     William Wyler          The Best Years of Our Lives      172.0\n",
       "4694     Peter Jackson                            King Kong      201.0\n",
       "4708  Michael Wadleigh                            Woodstock      215.0\n",
       "4747    Akira Kurosawa                        Seven Samurai      202.0\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[[\"director_name\",\"movie_title\",\"duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a2f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 color         director_name  num_critic_for_reviews  \\\n",
      "76               Color        Kevin Reynolds                    91.0   \n",
      "420              Color          Martin Brest                    98.0   \n",
      "499              Color         Kevin Costner                    79.0   \n",
      "606              Color         James Cameron                    82.0   \n",
      "698              Color       Lawrence Kasdan                    40.0   \n",
      "735              Color        Robert Redford                    96.0   \n",
      "883              Color           Ron Maxwell                    84.0   \n",
      "909              Color        Jonathan Demme                    78.0   \n",
      "1124             Color    Billy Bob Thornton                    85.0   \n",
      "1125   Black and White          Oliver Stone                    83.0   \n",
      "1429             Color             Spike Lee                    61.0   \n",
      "1501             Color       Taylor Hackford                    12.0   \n",
      "1523             Color         Warren Beatty                    57.0   \n",
      "1575             Color        Sydney Pollack                    66.0   \n",
      "1813             Color        Philip Kaufman                    80.0   \n",
      "1843   Black and White  Richard Attenborough                    56.0   \n",
      "1980             Color           Ron Maxwell                    22.0   \n",
      "2092             Color   Christopher Spencer                    61.0   \n",
      "2266             Color        George Stevens                    27.0   \n",
      "2356             Color         Kevin Costner                    92.0   \n",
      "2379             Color          Anthony Mann                    30.0   \n",
      "2487             Color          George Cukor                    82.0   \n",
      "2727             Color                   NaN                     9.0   \n",
      "3026             Color            David Lean                    89.0   \n",
      "3101   Black and White           Ken Annakin                    53.0   \n",
      "3267             Color        Stanley Kramer                    61.0   \n",
      "3280             Color        Norman Jewison                    66.0   \n",
      "3352             Color          Mervyn LeRoy                    54.0   \n",
      "3958             Color         Peter H. Hunt                    34.0   \n",
      "4077   Black and White        Stanley Kramer                    73.0   \n",
      "4113             Color                   NaN                    10.0   \n",
      "4238   Black and White         William Wyler                    97.0   \n",
      "4688             Color           Steve James                    53.0   \n",
      "4708             Color      Michael Wadleigh                    53.0   \n",
      "\n",
      "      duration  director_facebook_likes  actor_3_facebook_likes  \\\n",
      "76       176.0                     58.0                    60.0   \n",
      "420      178.0                    102.0                   551.0   \n",
      "499      177.0                      0.0                   582.0   \n",
      "606      171.0                      0.0                   638.0   \n",
      "698      212.0                    759.0                   812.0   \n",
      "735      170.0                      0.0                   380.0   \n",
      "883      280.0                     33.0                    67.0   \n",
      "909      172.0                    438.0                   466.0   \n",
      "1124     220.0                      0.0                   820.0   \n",
      "1125     212.0                      0.0                   805.0   \n",
      "1429     202.0                      0.0                   318.0   \n",
      "1501     330.0                    138.0                   672.0   \n",
      "1523     195.0                    631.0                   521.0   \n",
      "1575     161.0                    521.0                   184.0   \n",
      "1813     193.0                    133.0                   820.0   \n",
      "1843     175.0                      0.0                    14.0   \n",
      "1980     271.0                     33.0                   251.0   \n",
      "2092     170.0                     25.0                    55.0   \n",
      "2266     225.0                    126.0                   202.0   \n",
      "2356     236.0                      0.0                   232.0   \n",
      "2379     172.0                     75.0                   102.0   \n",
      "2487     170.0                    165.0                   244.0   \n",
      "2727     286.0                      NaN                   527.0   \n",
      "3026     200.0                    767.0                   382.0   \n",
      "3101     178.0                     19.0                   196.0   \n",
      "3267     197.0                    176.0                   760.0   \n",
      "3280     181.0                    278.0                    51.0   \n",
      "3352     171.0                     54.0                   346.0   \n",
      "3958     168.0                      0.0                    69.0   \n",
      "4077     186.0                    176.0                   760.0   \n",
      "4113     173.0                      NaN                   476.0   \n",
      "4238     172.0                    355.0                   188.0   \n",
      "4688     170.0                     23.0                     2.0   \n",
      "4708     215.0                     14.0                   136.0   \n",
      "\n",
      "                 actor_2_name  actor_1_facebook_likes        gross  \\\n",
      "76                Rick Aviles                   711.0   88246220.0   \n",
      "420                 Brad Pitt                 12000.0   44606335.0   \n",
      "499      Brian Anthony Wilson                   766.0   17593391.0   \n",
      "606                Todd Graff                  2000.0   54222000.0   \n",
      "698          Catherine O'Hara                  2000.0   25052000.0   \n",
      "735      Kristin Scott Thomas                 19000.0   75370763.0   \n",
      "883          Bruce Boxleitner                   789.0   12870569.0   \n",
      "909            Kimberly Elise                   852.0   22843047.0   \n",
      "1124             Henry Thomas                 13000.0   15527125.0   \n",
      "1125              Bob Hoskins                 12000.0   13560960.0   \n",
      "1429             Delroy Lindo                 18000.0   48169908.0   \n",
      "1501            Jesse Borrego                   848.0    4496583.0   \n",
      "1523            Warren Beatty                   635.0          NaN   \n",
      "1575            Michael Gough                 11000.0   87100000.0   \n",
      "1813              Scott Glenn                  2000.0   21500000.0   \n",
      "1843             Dirk Bogarde                   385.0   50800000.0   \n",
      "1980  William Morgan Sheppard                   854.0   10769960.0   \n",
      "2092         Amber Rose Revah                   329.0   59696176.0   \n",
      "2266            Carroll Baker                   940.0    8000000.0   \n",
      "2356           Michael Spears                   933.0  184208848.0   \n",
      "2379               Mel Ferrer                   617.0          NaN   \n",
      "2487             Rex Harrison                   453.0   72000000.0   \n",
      "2727            Tom Hollander                   857.0          NaN   \n",
      "3026             Klaus Kinski                   597.0  111722000.0   \n",
      "3101           Richard Beymer                   726.0          NaN   \n",
      "3267               Sid Caesar                   924.0   46300000.0   \n",
      "3280      Paul Michael Glaser                   402.0   50000000.0   \n",
      "3352             Deborah Kerr                   440.0          NaN   \n",
      "3958               Ken Howard                   713.0          NaN   \n",
      "4077         Montgomery Clift                   877.0          NaN   \n",
      "4113               Colm Feore                   723.0          NaN   \n",
      "4238            Teresa Wright                   749.0   23650000.0   \n",
      "4688              Arthur Agee                     7.0    7830611.0   \n",
      "4708             Jimi Hendrix                   262.0   13300000.0   \n",
      "\n",
      "                                       genres  ... num_user_for_reviews  \\\n",
      "76           Action|Adventure|Sci-Fi|Thriller  ...                309.0   \n",
      "420                     Drama|Fantasy|Romance  ...                703.0   \n",
      "499             Action|Adventure|Drama|Sci-Fi  ...                376.0   \n",
      "606           Adventure|Drama|Sci-Fi|Thriller  ...                380.0   \n",
      "698   Adventure|Biography|Crime|Drama|Western  ...                145.0   \n",
      "735                     Drama|Romance|Western  ...                263.0   \n",
      "883                         Drama|History|War  ...                497.0   \n",
      "909                      Drama|History|Horror  ...                207.0   \n",
      "1124                    Drama|Romance|Western  ...                183.0   \n",
      "1125                  Biography|Drama|History  ...                161.0   \n",
      "1429          Biography|Drama|History|Romance  ...                156.0   \n",
      "1501                              Crime|Drama  ...                129.0   \n",
      "1523          Biography|Drama|History|Romance  ...                127.0   \n",
      "1575                  Biography|Drama|Romance  ...                200.0   \n",
      "1813                  Adventure|Drama|History  ...                170.0   \n",
      "1843                        Drama|History|War  ...                210.0   \n",
      "1980                        Drama|History|War  ...                256.0   \n",
      "2092                  Biography|Drama|History  ...                174.0   \n",
      "2266                  Biography|Drama|History  ...                100.0   \n",
      "2356                  Adventure|Drama|Western  ...                382.0   \n",
      "2379                        Drama|History|War  ...                 91.0   \n",
      "2487             Drama|Family|Musical|Romance  ...                258.0   \n",
      "2727                   Drama|History|Thriller  ...                 39.0   \n",
      "3026                        Drama|Romance|War  ...                255.0   \n",
      "3101                 Action|Drama|History|War  ...                192.0   \n",
      "3267            Action|Adventure|Comedy|Crime  ...                344.0   \n",
      "3280             Drama|Family|Musical|Romance  ...                150.0   \n",
      "3352          Biography|Drama|History|Romance  ...                 90.0   \n",
      "3958             Drama|Family|History|Musical  ...                129.0   \n",
      "4077                                Drama|War  ...                176.0   \n",
      "4113                   Horror|Sci-Fi|Thriller  ...                 33.0   \n",
      "4238                        Drama|Romance|War  ...                235.0   \n",
      "4688                  Documentary|Drama|Sport  ...                 74.0   \n",
      "4708                Documentary|History|Music  ...                 63.0   \n",
      "\n",
      "     language  country  content_rating       budget  title_year  \\\n",
      "76    English      USA           PG-13  175000000.0      1995.0   \n",
      "420   English      USA           PG-13   90000000.0      1998.0   \n",
      "499   English      USA               R   80000000.0      1997.0   \n",
      "606   English      USA           PG-13   69500000.0      1989.0   \n",
      "698   English      USA           PG-13   63000000.0      1994.0   \n",
      "735   English      USA           PG-13   60000000.0      1998.0   \n",
      "883   English      USA           PG-13   56000000.0      2003.0   \n",
      "909   English      USA               R   55000000.0      1998.0   \n",
      "1124  English      USA           PG-13   57000000.0      2000.0   \n",
      "1125  English      USA               R   50000000.0      1995.0   \n",
      "1429  English      USA           PG-13   33000000.0      1992.0   \n",
      "1501  English      USA               R   35000000.0      1993.0   \n",
      "1523  English      USA              PG   35000000.0      1981.0   \n",
      "1575  English      USA              PG   31000000.0      1985.0   \n",
      "1813  English      USA              PG   27000000.0      1983.0   \n",
      "1843  English      USA              PG   26000000.0      1977.0   \n",
      "1980  English      USA              PG   25000000.0      1993.0   \n",
      "2092  English      USA           PG-13   22000000.0      2014.0   \n",
      "2266  English      USA               G   20000000.0      1965.0   \n",
      "2356  English      USA           PG-13   22000000.0      1990.0   \n",
      "2379  English      USA        Approved   19000000.0      1964.0   \n",
      "2487  English      USA        Approved   17000000.0      1964.0   \n",
      "2727  English      USA             NaN          NaN         NaN   \n",
      "3026  English      USA           PG-13   11000000.0      1965.0   \n",
      "3101  English      USA               G   10000000.0      1962.0   \n",
      "3267  English      USA        Approved    9400000.0      1963.0   \n",
      "3280  English      USA               G    9000000.0      1971.0   \n",
      "3352  English      USA          Passed    7623000.0      1951.0   \n",
      "3958  English      USA              PG    4000000.0      1972.0   \n",
      "4077  English      USA       Not Rated    3000000.0      1961.0   \n",
      "4113  English      USA             NaN          NaN         NaN   \n",
      "4238  English      USA       Not Rated    2100000.0      1946.0   \n",
      "4688  English      USA           PG-13     700000.0      1994.0   \n",
      "4708  English      USA               R     600000.0      1970.0   \n",
      "\n",
      "     actor_2_facebook_likes imdb_score  aspect_ratio movie_facebook_likes  \n",
      "76                     60.0        6.1          1.85                    0  \n",
      "420                 11000.0        7.1          1.85                10000  \n",
      "499                   674.0        6.0          2.35                    0  \n",
      "606                   650.0        7.6          2.35                    0  \n",
      "698                   925.0        6.6          2.35                    0  \n",
      "735                  1000.0        6.5          1.85                    0  \n",
      "883                   640.0        6.3          2.35                  953  \n",
      "909                   637.0        5.9          1.85                  853  \n",
      "1124                  861.0        5.8          2.35                  652  \n",
      "1125                 5000.0        7.1          2.35                  915  \n",
      "1429                  848.0        7.7          1.85                    0  \n",
      "1501                  674.0        8.0          1.66                 6000  \n",
      "1523                  631.0        7.5          1.85                    0  \n",
      "1575                  920.0        7.2          1.85                    0  \n",
      "1813                  826.0        7.9          1.85                    0  \n",
      "1843                  232.0        7.4          2.35                    0  \n",
      "1980                  702.0        7.7          1.85                    0  \n",
      "2092                  134.0        5.6          2.35                15000  \n",
      "2266                  208.0        6.6          2.76                 1000  \n",
      "2356                  839.0        8.0          2.35                    0  \n",
      "2379                  134.0        6.7          2.20                  560  \n",
      "2487                  272.0        7.9          2.20                    0  \n",
      "2727                  555.0        7.9          1.78                  733  \n",
      "3026                  396.0        8.0          2.35                 7000  \n",
      "3101                  249.0        7.8          2.35                    0  \n",
      "3267                  898.0        7.6          2.76                    0  \n",
      "3280                  343.0        8.0          2.35                    0  \n",
      "3352                  426.0        7.2          1.37                 1000  \n",
      "3958                  649.0        7.6          2.35                    0  \n",
      "4077                  862.0        8.3          1.75                    0  \n",
      "4113                  539.0        5.0          1.78                  518  \n",
      "4238                  208.0        8.1          1.37                    0  \n",
      "4688                    6.0        8.3          1.33                    0  \n",
      "4708                  227.0        8.1          2.20                    0  \n",
      "\n",
      "[34 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[(df.duration>160)&(df.num_critic_for_reviews<100)&(df.country==\"USA\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddb7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df[(df.duration>=160)&(df.duration<200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed01c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 color      director_name  num_critic_for_reviews  duration  \\\n",
      "0                Color      James Cameron                   723.0     178.0   \n",
      "1                Color     Gore Verbinski                   302.0     169.0   \n",
      "3                Color  Christopher Nolan                   813.0     164.0   \n",
      "10               Color        Zack Snyder                   673.0     183.0   \n",
      "11               Color       Bryan Singer                   434.0     169.0   \n",
      "...                ...                ...                     ...       ...   \n",
      "4238   Black and White      William Wyler                    97.0     172.0   \n",
      "4351             Color               Remo                    15.0     160.0   \n",
      "4572   Black and White     Khalid Mohamed                     1.0     167.0   \n",
      "4593             Color    Vivek Agnihotri                     4.0     160.0   \n",
      "4688             Color        Steve James                    53.0     170.0   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
      "0                         0.0                   855.0  Joel David Moore   \n",
      "1                       563.0                  1000.0     Orlando Bloom   \n",
      "3                     22000.0                 23000.0    Christian Bale   \n",
      "10                        0.0                  2000.0      Lauren Cohan   \n",
      "11                        0.0                   903.0     Marlon Brando   \n",
      "...                       ...                     ...               ...   \n",
      "4238                    355.0                   188.0     Teresa Wright   \n",
      "4351                    168.0                    71.0              Remo   \n",
      "4572                     10.0                    97.0    Manoj Bajpayee   \n",
      "4593                      5.0                   219.0       Anil Kapoor   \n",
      "4688                     23.0                     2.0       Arthur Agee   \n",
      "\n",
      "      actor_1_facebook_likes        gross                           genres  \\\n",
      "0                     1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
      "1                    40000.0  309404152.0         Action|Adventure|Fantasy   \n",
      "3                    27000.0  448130642.0                  Action|Thriller   \n",
      "10                   15000.0  330249062.0          Action|Adventure|Sci-Fi   \n",
      "11                   18000.0  200069408.0          Action|Adventure|Sci-Fi   \n",
      "...                      ...          ...                              ...   \n",
      "4238                   749.0   23650000.0                Drama|Romance|War   \n",
      "4351                   733.0      95236.0                    Drama|Musical   \n",
      "4572                   353.0     610991.0                    Drama|Romance   \n",
      "4593                   724.0      49000.0                         Thriller   \n",
      "4688                     7.0    7830611.0          Documentary|Drama|Sport   \n",
      "\n",
      "      ... num_user_for_reviews language  country  content_rating       budget  \\\n",
      "0     ...               3054.0  English      USA           PG-13  237000000.0   \n",
      "1     ...               1238.0  English      USA           PG-13  300000000.0   \n",
      "3     ...               2701.0  English      USA           PG-13  250000000.0   \n",
      "10    ...               3018.0  English      USA           PG-13  250000000.0   \n",
      "11    ...               2367.0  English      USA           PG-13  209000000.0   \n",
      "...   ...                  ...      ...      ...             ...          ...   \n",
      "4238  ...                235.0  English      USA       Not Rated    2100000.0   \n",
      "4351  ...                 38.0    Hindi    India       Not Rated          NaN   \n",
      "4572  ...                 19.0    Hindi    India             NaN    1000000.0   \n",
      "4593  ...                 30.0    Hindi    India             NaN    1500000.0   \n",
      "4688  ...                 74.0  English      USA           PG-13     700000.0   \n",
      "\n",
      "      title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "0         2009.0                  936.0        7.9          1.78   \n",
      "1         2007.0                 5000.0        7.1          2.35   \n",
      "3         2012.0                23000.0        8.5          2.35   \n",
      "10        2016.0                 4000.0        6.9          2.35   \n",
      "11        2006.0                10000.0        6.1          2.35   \n",
      "...          ...                    ...        ...           ...   \n",
      "4238      1946.0                  208.0        8.1          1.37   \n",
      "4351      2013.0                  168.0        6.4           NaN   \n",
      "4572      2000.0                  186.0        6.2          2.35   \n",
      "4593      2005.0                  668.0        4.8           NaN   \n",
      "4688      1994.0                    6.0        8.3          1.33   \n",
      "\n",
      "     movie_facebook_likes  \n",
      "0                   33000  \n",
      "1                       0  \n",
      "3                  164000  \n",
      "10                 197000  \n",
      "11                      0  \n",
      "...                   ...  \n",
      "4238                    0  \n",
      "4351                 1000  \n",
      "4572                   92  \n",
      "4593                   31  \n",
      "4688                    0  \n",
      "\n",
      "[103 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554180c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          director_name                                movie_title  duration\n",
      "0         James Cameron                                    Avatar      178.0\n",
      "1        Gore Verbinski  Pirates of the Caribbean: At World's End      169.0\n",
      "3     Christopher Nolan                     The Dark Knight Rises      164.0\n",
      "10          Zack Snyder        Batman v Superman: Dawn of Justice      183.0\n",
      "11         Bryan Singer                          Superman Returns      169.0\n",
      "...                 ...                                        ...       ...\n",
      "4238      William Wyler               The Best Years of Our Lives      172.0\n",
      "4351               Remo                 ABCD (Any Body Can Dance)      160.0\n",
      "4572     Khalid Mohamed                                      Fiza      167.0\n",
      "4593    Vivek Agnihotri              Chocolate: Deep Dark Secrets      160.0\n",
      "4688        Steve James                               Hoop Dreams      170.0\n",
      "\n",
      "[103 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dt[[\"director_name\",\"movie_title\",\"duration\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d957d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607     Wall Street: Money Never Sleeps \n",
      "669                     Mona Lisa Smile \n",
      "683                          Fight Club \n",
      "751                      A Civil Action \n",
      "1147                  Finding Forrester \n",
      "                      ...               \n",
      "5003                 The Exploding Girl \n",
      "5018                           Flywheel \n",
      "5022               Stories of Our Lives \n",
      "5027                         The Circle \n",
      "5030                     On the Downlow \n",
      "Name: movie_title, Length: 236, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dt=df[df.genres==\"Drama\"]\n",
    "print(dt[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07521df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3        The Dark Knight Rises \n",
      "225               Jason Bourne \n",
      "347     A Good Day to Die Hard \n",
      "354                Unstoppable \n",
      "591                 Die Hard 2 \n",
      "                 ...           \n",
      "5003        The Exploding Girl \n",
      "5018                  Flywheel \n",
      "5022      Stories of Our Lives \n",
      "5027                The Circle \n",
      "5030            On the Downlow \n",
      "Name: movie_title, Length: 266, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dt=df[(df.genres==\"Drama\")|(df.genres==\"Action|Thriller\")]\n",
    "print(dt[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230579e2",
   "metadata": {},
   "source": [
    "# Handling NaN (null) Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d03dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4499190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04cf440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      color  director_name  num_critic_for_reviews  duration  \\\n",
      "0     False          False                   False     False   \n",
      "1     False          False                   False     False   \n",
      "2     False          False                   False     False   \n",
      "3     False          False                   False     False   \n",
      "4      True          False                    True      True   \n",
      "...     ...            ...                     ...       ...   \n",
      "5038  False          False                   False     False   \n",
      "5039  False           True                   False     False   \n",
      "5040  False          False                   False     False   \n",
      "5041  False          False                   False     False   \n",
      "5042  False          False                   False     False   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes  actor_2_name  \\\n",
      "0                       False                   False         False   \n",
      "1                       False                   False         False   \n",
      "2                       False                   False         False   \n",
      "3                       False                   False         False   \n",
      "4                       False                    True         False   \n",
      "...                       ...                     ...           ...   \n",
      "5038                    False                   False         False   \n",
      "5039                     True                   False         False   \n",
      "5040                    False                   False         False   \n",
      "5041                    False                   False         False   \n",
      "5042                    False                   False         False   \n",
      "\n",
      "      actor_1_facebook_likes  gross  genres  ...  num_user_for_reviews  \\\n",
      "0                      False  False   False  ...                 False   \n",
      "1                      False  False   False  ...                 False   \n",
      "2                      False  False   False  ...                 False   \n",
      "3                      False  False   False  ...                 False   \n",
      "4                      False   True   False  ...                  True   \n",
      "...                      ...    ...     ...  ...                   ...   \n",
      "5038                   False   True   False  ...                 False   \n",
      "5039                   False   True   False  ...                 False   \n",
      "5040                   False   True   False  ...                 False   \n",
      "5041                   False  False   False  ...                 False   \n",
      "5042                   False  False   False  ...                 False   \n",
      "\n",
      "      language  country  content_rating  budget  title_year  \\\n",
      "0        False    False           False   False       False   \n",
      "1        False    False           False   False       False   \n",
      "2        False    False           False   False       False   \n",
      "3        False    False           False   False       False   \n",
      "4         True     True            True    True        True   \n",
      "...        ...      ...             ...     ...         ...   \n",
      "5038     False    False            True    True       False   \n",
      "5039     False    False           False    True        True   \n",
      "5040     False    False            True   False       False   \n",
      "5041     False    False           False    True       False   \n",
      "5042     False    False           False   False       False   \n",
      "\n",
      "      actor_2_facebook_likes  imdb_score  aspect_ratio  movie_facebook_likes  \n",
      "0                      False       False         False                 False  \n",
      "1                      False       False         False                 False  \n",
      "2                      False       False         False                 False  \n",
      "3                      False       False         False                 False  \n",
      "4                      False       False          True                 False  \n",
      "...                      ...         ...           ...                   ...  \n",
      "5038                   False       False          True                 False  \n",
      "5039                   False       False         False                 False  \n",
      "5040                   False       False          True                 False  \n",
      "5041                   False       False         False                 False  \n",
      "5042                   False       False         False                 False  \n",
      "\n",
      "[5043 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull()) #Gives the data as True if it finds an null or NaN value in the dataset else gives the data as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae56d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      color  director_name  num_critic_for_reviews  duration  \\\n",
      "0      True           True                    True      True   \n",
      "1      True           True                    True      True   \n",
      "2      True           True                    True      True   \n",
      "3      True           True                    True      True   \n",
      "4     False           True                   False     False   \n",
      "...     ...            ...                     ...       ...   \n",
      "5038   True           True                    True      True   \n",
      "5039   True          False                    True      True   \n",
      "5040   True           True                    True      True   \n",
      "5041   True           True                    True      True   \n",
      "5042   True           True                    True      True   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes  actor_2_name  \\\n",
      "0                        True                    True          True   \n",
      "1                        True                    True          True   \n",
      "2                        True                    True          True   \n",
      "3                        True                    True          True   \n",
      "4                        True                   False          True   \n",
      "...                       ...                     ...           ...   \n",
      "5038                     True                    True          True   \n",
      "5039                    False                    True          True   \n",
      "5040                     True                    True          True   \n",
      "5041                     True                    True          True   \n",
      "5042                     True                    True          True   \n",
      "\n",
      "      actor_1_facebook_likes  gross  genres  ...  num_user_for_reviews  \\\n",
      "0                       True   True    True  ...                  True   \n",
      "1                       True   True    True  ...                  True   \n",
      "2                       True   True    True  ...                  True   \n",
      "3                       True   True    True  ...                  True   \n",
      "4                       True  False    True  ...                 False   \n",
      "...                      ...    ...     ...  ...                   ...   \n",
      "5038                    True  False    True  ...                  True   \n",
      "5039                    True  False    True  ...                  True   \n",
      "5040                    True  False    True  ...                  True   \n",
      "5041                    True   True    True  ...                  True   \n",
      "5042                    True   True    True  ...                  True   \n",
      "\n",
      "      language  country  content_rating  budget  title_year  \\\n",
      "0         True     True            True    True        True   \n",
      "1         True     True            True    True        True   \n",
      "2         True     True            True    True        True   \n",
      "3         True     True            True    True        True   \n",
      "4        False    False           False   False       False   \n",
      "...        ...      ...             ...     ...         ...   \n",
      "5038      True     True           False   False        True   \n",
      "5039      True     True            True   False       False   \n",
      "5040      True     True           False    True        True   \n",
      "5041      True     True            True   False        True   \n",
      "5042      True     True            True    True        True   \n",
      "\n",
      "      actor_2_facebook_likes  imdb_score  aspect_ratio  movie_facebook_likes  \n",
      "0                       True        True          True                  True  \n",
      "1                       True        True          True                  True  \n",
      "2                       True        True          True                  True  \n",
      "3                       True        True          True                  True  \n",
      "4                       True        True         False                  True  \n",
      "...                      ...         ...           ...                   ...  \n",
      "5038                    True        True         False                  True  \n",
      "5039                    True        True          True                  True  \n",
      "5040                    True        True         False                  True  \n",
      "5041                    True        True          True                  True  \n",
      "5042                    True        True          True                  True  \n",
      "\n",
      "[5043 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.notnull()) #Gives the data as False if it finds an null or NaN value in the dataset else gives the data as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df976ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color                         19\n",
      "director_name                104\n",
      "num_critic_for_reviews        50\n",
      "duration                      15\n",
      "director_facebook_likes      104\n",
      "actor_3_facebook_likes        23\n",
      "actor_2_name                  13\n",
      "actor_1_facebook_likes         7\n",
      "gross                        884\n",
      "genres                         0\n",
      "actor_1_name                   7\n",
      "movie_title                    0\n",
      "num_voted_users                0\n",
      "cast_total_facebook_likes      0\n",
      "actor_3_name                  23\n",
      "facenumber_in_poster          13\n",
      "plot_keywords                153\n",
      "movie_imdb_link                0\n",
      "num_user_for_reviews          21\n",
      "language                      12\n",
      "country                        5\n",
      "content_rating               303\n",
      "budget                       492\n",
      "title_year                   108\n",
      "actor_2_facebook_likes        13\n",
      "imdb_score                     0\n",
      "aspect_ratio                 329\n",
      "movie_facebook_likes           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum()) #Gives the count of null or NaN values for every column in the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb99bdd",
   "metadata": {},
   "source": [
    "# Handling Missing values of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7d41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8ecb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8262d181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    USA\n",
      "1    USA\n",
      "2     UK\n",
      "3    USA\n",
      "4    NaN\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"country\"].head()) #printing the first five rows in the column country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941655bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values before FillNA : 5\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values before FillNA :\",df[\"country\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c01b98ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      USA\n",
      "1      USA\n",
      "2       UK\n",
      "3      USA\n",
      "4    INDIA\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.country=df.country.fillna(\"INDIA\") #In the column country, it fills INDIA whereever it finds null or NaN value\n",
    "print(df.country.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac866246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after FillNA : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values after FillNA :\",df[\"country\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5fb38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"Data/movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54116c2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    USA\n",
      "1    USA\n",
      "2     UK\n",
      "3    USA\n",
      "4    USA\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1.country=df1.country.fillna(df1.country.mode()[0]) #Using .mode() function to fill the null value with highest frequency in the data set\n",
    "print(df1.country.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2b404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    USA\n",
      "1    USA\n",
      "2     UK\n",
      "3    USA\n",
      "4    USA\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1[\"country\"].fillna(df1[\"country\"].mode()[0],inplace=True) #This is the standard procedure to fill null value and same as above procedure\n",
    "print(df1.country.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36182b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after FillNA : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values after FillNA :\",df1[\"country\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32dcd04",
   "metadata": {},
   "source": [
    "# Handling Missing values of Numarical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46850729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c880c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/movie_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1c7163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     178.0\n",
      "1     169.0\n",
      "2     148.0\n",
      "3     164.0\n",
      "4       NaN\n",
      "5     132.0\n",
      "6     156.0\n",
      "7     100.0\n",
      "8     141.0\n",
      "9     153.0\n",
      "10    183.0\n",
      "11    169.0\n",
      "12    106.0\n",
      "13    151.0\n",
      "14    150.0\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"duration\"].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7153e300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values before FillNA : 15\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values before FillNA :\",df[\"duration\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d516c946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of duration : 107.2010739856802\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of duration :\",df.duration.mean()) #Finding the mean of the column duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdd23e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of duration : 107\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of duration :\",round(df.duration.mean())) #round function gives the round figure for the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c0cc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of duration : 107.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of duration :\",round(df.duration.mean(),1)) #we can get required no.of fractional values by specifying them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc82753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     178.0\n",
      "1     169.0\n",
      "2     148.0\n",
      "3     164.0\n",
      "4     107.2\n",
      "5     132.0\n",
      "6     156.0\n",
      "7     100.0\n",
      "8     141.0\n",
      "9     153.0\n",
      "10    183.0\n",
      "11    169.0\n",
      "12    106.0\n",
      "13    151.0\n",
      "14    150.0\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df.duration=df.duration.fillna(round(df.duration.mean(),1)) ##Using .mode() function to fill the null value with highest frequency in the data set\n",
    "print(df.duration.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "636207fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     178.0\n",
      "1     169.0\n",
      "2     148.0\n",
      "3     164.0\n",
      "4     107.2\n",
      "5     132.0\n",
      "6     156.0\n",
      "7     100.0\n",
      "8     141.0\n",
      "9     153.0\n",
      "10    183.0\n",
      "11    169.0\n",
      "12    106.0\n",
      "13    151.0\n",
      "14    150.0\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df[\"duration\"].fillna(round(df[\"duration\"].mean(),1),inplace=True) #This is the standard procedure to fill null value and same as above procedure\n",
    "print(df.duration.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e742fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values after FillNA : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values after FillNA :\",df[\"duration\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea73cde",
   "metadata": {},
   "source": [
    "# Handling Missing data in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b56deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a35bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  name   phone address    m1  m2    m3    m4\n",
      "0    101  anand    999     hyd  87.0  55   NaN  44.0\n",
      "1    105    aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109    rrr    444     vik   NaN  78  88.0  88.0\n",
      "3    107    sss    888     sec  69.0  85  58.0   NaN\n",
      "4    201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "5    202    aaa    555     vij   NaN  66  99.0   NaN\n",
      "6    203    rrr    444     vik  89.0  78  88.0  88.0\n",
      "7    204    NaN    888     NaN  33.0  77  58.0   NaN\n",
      "8    205    bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/stddatacsv.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d595a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regno      0\n",
      "name       1\n",
      "phone      0\n",
      "address    1\n",
      "m1         2\n",
      "m2         0\n",
      "m3         2\n",
      "m4         3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf457c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filling nullvalues regno      0\n",
      "name       1\n",
      "phone      0\n",
      "address    1\n",
      "m1         0\n",
      "m2         0\n",
      "m3         0\n",
      "m4         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.m1.fillna(round(df.m1.mean()),inplace=True)\n",
    "df.m3.fillna(round(df.m3.mean()),inplace=True)\n",
    "df.m4.fillna(round(df.m4.mean()),inplace=True)\n",
    "print(\"After filling nullvalues\",df.isna().sum()) #Both .isna() and .isnull() are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4da86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regno</th>\n",
       "      <th>name</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>anand</td>\n",
       "      <td>999</td>\n",
       "      <td>hyd</td>\n",
       "      <td>87.0</td>\n",
       "      <td>55</td>\n",
       "      <td>84.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>aaa</td>\n",
       "      <td>555</td>\n",
       "      <td>vij</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>rrr</td>\n",
       "      <td>444</td>\n",
       "      <td>vik</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>sss</td>\n",
       "      <td>888</td>\n",
       "      <td>sec</td>\n",
       "      <td>69.0</td>\n",
       "      <td>85</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>anand</td>\n",
       "      <td>999</td>\n",
       "      <td>hyd</td>\n",
       "      <td>87.0</td>\n",
       "      <td>55</td>\n",
       "      <td>84.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202</td>\n",
       "      <td>aaa</td>\n",
       "      <td>555</td>\n",
       "      <td>vij</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66</td>\n",
       "      <td>99.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>203</td>\n",
       "      <td>rrr</td>\n",
       "      <td>444</td>\n",
       "      <td>vik</td>\n",
       "      <td>89.0</td>\n",
       "      <td>78</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>77</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>205</td>\n",
       "      <td>bbb</td>\n",
       "      <td>111</td>\n",
       "      <td>ant</td>\n",
       "      <td>77.0</td>\n",
       "      <td>88</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regno  name   phone address    m1  m2    m3    m4\n",
       "0    101  anand    999     hyd  87.0  55  84.0  44.0\n",
       "1    105    aaa    555     vij  77.0  66  99.0  99.0\n",
       "2    109    rrr    444     vik  74.0  78  88.0  88.0\n",
       "3    107    sss    888     sec  69.0  85  58.0  77.0\n",
       "4    201  anand    999     hyd  87.0  55  84.0  44.0\n",
       "5    202    aaa    555     vij  74.0  66  99.0  77.0\n",
       "6    203    rrr    444     vik  89.0  78  88.0  88.0\n",
       "7    204    NaN    888     NaN  33.0  77  58.0  77.0\n",
       "8    205    bbb    111     ant  77.0  88  99.0  99.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96232ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"Data/stddatacsv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cef1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropna() function :\n",
      "    regno  name   phone address    m1  m2    m3    m4\n",
      "0    101  anand    999     hyd  87.0  55   NaN  44.0\n",
      "1    105    aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109    rrr    444     vik   NaN  78  88.0  88.0\n",
      "3    107    sss    888     sec  69.0  85  58.0   NaN\n",
      "4    201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "5    202    aaa    555     vij   NaN  66  99.0   NaN\n",
      "6    203    rrr    444     vik  89.0  78  88.0  88.0\n",
      "7    204    NaN    888     NaN  33.0  77  58.0   NaN\n",
      "8    205    bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Before dropna() function :\\n\",df1) #Actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10066e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df1.dropna() #Drop the rows which contains null or nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f0b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno name   phone address    m1  m2    m3    m4\n",
      "1    105   aaa    555     vij  77.0  66  99.0  99.0\n",
      "6    203   rrr    444     vik  89.0  78  88.0  88.0\n",
      "8    205   bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3704e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=dt.reset_index() #Re-assign the index values and consider the old indexing as another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34cfca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropna() function and re-assigning index values :\n",
      "    index  regno name   phone address    m1  m2    m3    m4\n",
      "0      1    105   aaa    555     vij  77.0  66  99.0  99.0\n",
      "1      6    203   rrr    444     vik  89.0  78  88.0  88.0\n",
      "2      8    205   bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(\"After dropna() function and re-assigning index values :\\n\",dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed313f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    regno  name   phone address    m1    m2    m3    m4\n",
      "0   101.0  anand  999.0     hyd  87.0  55.0   NaN  44.0\n",
      "1   105.0    aaa  555.0     vij  77.0  66.0  99.0  99.0\n",
      "2     NaN    NaN    NaN     NaN   NaN   NaN   NaN   NaN\n",
      "3   109.0    rrr  444.0     vik   NaN  78.0  88.0  88.0\n",
      "4   107.0    sss  888.0     sec  69.0  85.0  58.0   NaN\n",
      "5     NaN    NaN    NaN     NaN   NaN   NaN   NaN   NaN\n",
      "6   201.0  anand  999.0     hyd  87.0  55.0   NaN  44.0\n",
      "7   202.0    aaa  555.0     vij   NaN  66.0  99.0   NaN\n",
      "8   203.0    rrr  444.0     vik  89.0  78.0  88.0  88.0\n",
      "9     NaN    NaN    NaN     NaN   NaN   NaN   NaN   NaN\n",
      "10  204.0    NaN  888.0     NaN  33.0  77.0  58.0   NaN\n",
      "11  205.0    bbb  111.0     ant  77.0  88.0  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "df2=pd.read_csv(\"Data/stddatacsv.csv\") #Dataset having empty rows\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9b38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df2.dropna(how=\"all\") #Drop the rows having all null or nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad9c4f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropna() function with How=all :\n",
      "     regno  name   phone address    m1    m2    m3    m4\n",
      "0   101.0  anand  999.0     hyd  87.0  55.0   NaN  44.0\n",
      "1   105.0    aaa  555.0     vij  77.0  66.0  99.0  99.0\n",
      "3   109.0    rrr  444.0     vik   NaN  78.0  88.0  88.0\n",
      "4   107.0    sss  888.0     sec  69.0  85.0  58.0   NaN\n",
      "6   201.0  anand  999.0     hyd  87.0  55.0   NaN  44.0\n",
      "7   202.0    aaa  555.0     vij   NaN  66.0  99.0   NaN\n",
      "8   203.0    rrr  444.0     vik  89.0  78.0  88.0  88.0\n",
      "10  204.0    NaN  888.0     NaN  33.0  77.0  58.0   NaN\n",
      "11  205.0    bbb  111.0     ant  77.0  88.0  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropna() function with How=all :\\n\",dt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f2a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    regno  name   phone address    m1  m2    m3    m4\n",
      "0     101  anand    999     hyd  87.0  55   NaN  44.0\n",
      "1     105    aaa    555     vij  77.0  66  99.0  99.0\n",
      "2     109    rrr    444     vik   NaN  78  88.0  88.0\n",
      "3     107    sss    888     sec  69.0  85  58.0   NaN\n",
      "4     201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "5     201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "6     202    aaa    555     vij   NaN  66  99.0   NaN\n",
      "7     203    rrr    444     vik  89.0  78  88.0  88.0\n",
      "8     204    NaN    888     NaN  33.0  77  58.0   NaN\n",
      "9     205    bbb    111     ant  77.0  88  99.0  99.0\n",
      "10    205    bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "df3=pd.read_csv(\"Data/stddatacsv.csv\") #Dataset having repeated rows or duplicates\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a1789ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droping duplicate records :\n",
      "    regno  name   phone address    m1  m2    m3    m4\n",
      "0    101  anand    999     hyd  87.0  55   NaN  44.0\n",
      "1    105    aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109    rrr    444     vik   NaN  78  88.0  88.0\n",
      "3    107    sss    888     sec  69.0  85  58.0   NaN\n",
      "4    201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "6    202    aaa    555     vij   NaN  66  99.0   NaN\n",
      "7    203    rrr    444     vik  89.0  78  88.0  88.0\n",
      "8    204    NaN    888     NaN  33.0  77  58.0   NaN\n",
      "9    205    bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Droping duplicate records :\\n\",df3.drop_duplicates()) #Drops the repeated rows or duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45b37e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.read_csv(\"Data/stddatacsv.csv\") #Actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1af1ff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  name   phone address    m1  m2    m3    m4\n",
      "0    101  anand    999     hyd  87.0  55   NaN  44.0\n",
      "1    105    aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109    rrr    444     vik   NaN  78  88.0  88.0\n",
      "3    107    sss    888     sec  69.0  85  58.0   NaN\n",
      "4    201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "5    202    aaa    555     vij   NaN  66  99.0   NaN\n",
      "6    203    rrr    444     vik  89.0  78  88.0  88.0\n",
      "8    205    bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(df4.dropna(thresh=6)) #Drops the row if it contains less than 6 values since we are giving thresh = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5081077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno name   phone address    m1  m2    m3    m4\n",
      "1    105   aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109   rrr    444     vik   NaN  78  88.0  88.0\n",
      "3    107   sss    888     sec  69.0  85  58.0   NaN\n",
      "5    202   aaa    555     vij   NaN  66  99.0   NaN\n",
      "6    203   rrr    444     vik  89.0  78  88.0  88.0\n",
      "7    204   NaN    888     NaN  33.0  77  58.0   NaN\n",
      "8    205   bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(df4.dropna(subset=[\"m3\"])) #Drops the rows containing null oe nan values with respect to column m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a31759f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno name   phone address    m1  m2    m3    m4\n",
      "1    105   aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109   rrr    444     vik   NaN  78  88.0  88.0\n",
      "6    203   rrr    444     vik  89.0  78  88.0  88.0\n",
      "8    205   bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(df4.dropna(subset=[\"m3\",\"m4\"])) #Drops the rows containing null oe nan values with respect to columns m3 and m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2e7768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  name   father's name  phone address    m1  m2    m3    m4\n",
      "0    101  anand            NaN    999     hyd  87.0  55   NaN  44.0\n",
      "1    105    aaa            NaN    555     vij  77.0  66  99.0  99.0\n",
      "2    109    rrr            NaN    444     vik   NaN  78  88.0  88.0\n",
      "3    107    sss            NaN    888     sec  69.0  85  58.0   NaN\n",
      "4    201  anand            NaN    999     hyd  87.0  55   NaN  44.0\n",
      "5    202    aaa            NaN    555     vij   NaN  66  99.0   NaN\n",
      "6    203    rrr            NaN    444     vik  89.0  78  88.0  88.0\n",
      "7    204    NaN            NaN    888     NaN  33.0  77  58.0   NaN\n",
      "8    205    bbb            NaN    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "df5=pd.read_csv(\"Data/stddatacsv.csv\") #Dataset containing empty column\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6733cdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  name   phone address    m1  m2    m3    m4\n",
      "0    101  anand    999     hyd  87.0  55   NaN  44.0\n",
      "1    105    aaa    555     vij  77.0  66  99.0  99.0\n",
      "2    109    rrr    444     vik   NaN  78  88.0  88.0\n",
      "3    107    sss    888     sec  69.0  85  58.0   NaN\n",
      "4    201  anand    999     hyd  87.0  55   NaN  44.0\n",
      "5    202    aaa    555     vij   NaN  66  99.0   NaN\n",
      "6    203    rrr    444     vik  89.0  78  88.0  88.0\n",
      "7    204    NaN    888     NaN  33.0  77  58.0   NaN\n",
      "8    205    bbb    111     ant  77.0  88  99.0  99.0\n"
     ]
    }
   ],
   "source": [
    "print(df5.dropna(axis=1,how=\"all\")) #Drops the empty column in the dataset and axis = 1 represents columns and axis = 0 represents rows and if we didn't specify axis by default it will consider rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcf820cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  phone  m2\n",
      "0    101    999  55\n",
      "1    105    555  66\n",
      "2    109    444  78\n",
      "3    107    888  85\n",
      "4    201    999  55\n",
      "5    202    555  66\n",
      "6    203    444  78\n",
      "7    204    888  77\n",
      "8    205    111  88\n"
     ]
    }
   ],
   "source": [
    "print(df5.dropna(axis=1)) #If we didnt specify how = \"all\" it will not only drops empty columns but also drops the columns having atleast one null or nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d37d150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   regno  name   phone address  m2\n",
      "0    101  anand    999     hyd  55\n",
      "1    105    aaa    555     vij  66\n",
      "2    109    rrr    444     vik  78\n",
      "3    107    sss    888     sec  85\n",
      "4    201  anand    999     hyd  55\n",
      "5    202    aaa    555     vij  66\n",
      "6    203    rrr    444     vik  78\n",
      "7    204    NaN    888     NaN  77\n",
      "8    205    bbb    111     ant  88\n"
     ]
    }
   ],
   "source": [
    "print(df5.dropna(axis=1,thresh=8)) #Drops the columns if it contains less than 8 values since we are giving thresh = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7871b58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color      director_name  num_critic_for_reviews  duration  \\\n",
      "0  Color      James Cameron                   723.0     178.0   \n",
      "1  Color     Gore Verbinski                   302.0     169.0   \n",
      "2  Color         Sam Mendes                   602.0     148.0   \n",
      "3  Color  Christopher Nolan                   813.0     164.0   \n",
      "4    NaN        Doug Walker                     NaN       NaN   \n",
      "\n",
      "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
      "0                      0.0                   855.0  Joel David Moore   \n",
      "1                    563.0                  1000.0     Orlando Bloom   \n",
      "2                      0.0                   161.0      Rory Kinnear   \n",
      "3                  22000.0                 23000.0    Christian Bale   \n",
      "4                    131.0                     NaN        Rob Walker   \n",
      "\n",
      "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
      "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
      "1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n",
      "2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
      "3                 27000.0  448130642.0                  Action|Thriller  ...   \n",
      "4                   131.0          NaN                      Documentary  ...   \n",
      "\n",
      "  num_user_for_reviews language  country  content_rating       budget  \\\n",
      "0               3054.0  English      USA           PG-13  237000000.0   \n",
      "1               1238.0  English      USA           PG-13  300000000.0   \n",
      "2                994.0  English       UK           PG-13  245000000.0   \n",
      "3               2701.0  English      USA           PG-13  250000000.0   \n",
      "4                  NaN      NaN      NaN             NaN          NaN   \n",
      "\n",
      "   title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "0      2009.0                  936.0        7.9          1.78   \n",
      "1      2007.0                 5000.0        7.1          2.35   \n",
      "2      2015.0                  393.0        6.8          2.35   \n",
      "3      2012.0                23000.0        8.5          2.35   \n",
      "4         NaN                   12.0        7.1           NaN   \n",
      "\n",
      "  movie_facebook_likes  \n",
      "0                33000  \n",
      "1                    0  \n",
      "2                85000  \n",
      "3               164000  \n",
      "4                    0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "DF=pd.read_csv(\"Data/movie_metadata.csv\")\n",
    "print(DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d71fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"director_name\"] = DF[\"director_name\"].str.upper() #Converts letters to upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3657928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color      director_name  num_critic_for_reviews  duration  \\\n",
      "0  Color      JAMES CAMERON                   723.0     178.0   \n",
      "1  Color     GORE VERBINSKI                   302.0     169.0   \n",
      "2  Color         SAM MENDES                   602.0     148.0   \n",
      "3  Color  CHRISTOPHER NOLAN                   813.0     164.0   \n",
      "4    NaN        DOUG WALKER                     NaN       NaN   \n",
      "5  Color     ANDREW STANTON                   462.0     132.0   \n",
      "6  Color          SAM RAIMI                   392.0     156.0   \n",
      "7  Color       NATHAN GRENO                   324.0     100.0   \n",
      "8  Color        JOSS WHEDON                   635.0     141.0   \n",
      "9  Color        DAVID YATES                   375.0     153.0   \n",
      "\n",
      "   director_facebook_likes  actor_3_facebook_likes       actor_2_name  \\\n",
      "0                      0.0                   855.0   Joel David Moore   \n",
      "1                    563.0                  1000.0      Orlando Bloom   \n",
      "2                      0.0                   161.0       Rory Kinnear   \n",
      "3                  22000.0                 23000.0     Christian Bale   \n",
      "4                    131.0                     NaN         Rob Walker   \n",
      "5                    475.0                   530.0    Samantha Morton   \n",
      "6                      0.0                  4000.0       James Franco   \n",
      "7                     15.0                   284.0       Donna Murphy   \n",
      "8                      0.0                 19000.0  Robert Downey Jr.   \n",
      "9                    282.0                 10000.0   Daniel Radcliffe   \n",
      "\n",
      "   actor_1_facebook_likes        gross  \\\n",
      "0                  1000.0  760505847.0   \n",
      "1                 40000.0  309404152.0   \n",
      "2                 11000.0  200074175.0   \n",
      "3                 27000.0  448130642.0   \n",
      "4                   131.0          NaN   \n",
      "5                   640.0   73058679.0   \n",
      "6                 24000.0  336530303.0   \n",
      "7                   799.0  200807262.0   \n",
      "8                 26000.0  458991599.0   \n",
      "9                 25000.0  301956980.0   \n",
      "\n",
      "                                              genres  ...  \\\n",
      "0                    Action|Adventure|Fantasy|Sci-Fi  ...   \n",
      "1                           Action|Adventure|Fantasy  ...   \n",
      "2                          Action|Adventure|Thriller  ...   \n",
      "3                                    Action|Thriller  ...   \n",
      "4                                        Documentary  ...   \n",
      "5                            Action|Adventure|Sci-Fi  ...   \n",
      "6                           Action|Adventure|Romance  ...   \n",
      "7  Adventure|Animation|Comedy|Family|Fantasy|Musi...  ...   \n",
      "8                            Action|Adventure|Sci-Fi  ...   \n",
      "9                   Adventure|Family|Fantasy|Mystery  ...   \n",
      "\n",
      "  num_user_for_reviews language  country  content_rating       budget  \\\n",
      "0               3054.0  English      USA           PG-13  237000000.0   \n",
      "1               1238.0  English      USA           PG-13  300000000.0   \n",
      "2                994.0  English       UK           PG-13  245000000.0   \n",
      "3               2701.0  English      USA           PG-13  250000000.0   \n",
      "4                  NaN      NaN      NaN             NaN          NaN   \n",
      "5                738.0  English      USA           PG-13  263700000.0   \n",
      "6               1902.0  English      USA           PG-13  258000000.0   \n",
      "7                387.0  English      USA              PG  260000000.0   \n",
      "8               1117.0  English      USA           PG-13  250000000.0   \n",
      "9                973.0  English       UK              PG  250000000.0   \n",
      "\n",
      "   title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "0      2009.0                  936.0        7.9          1.78   \n",
      "1      2007.0                 5000.0        7.1          2.35   \n",
      "2      2015.0                  393.0        6.8          2.35   \n",
      "3      2012.0                23000.0        8.5          2.35   \n",
      "4         NaN                   12.0        7.1           NaN   \n",
      "5      2012.0                  632.0        6.6          2.35   \n",
      "6      2007.0                11000.0        6.2          2.35   \n",
      "7      2010.0                  553.0        7.8          1.85   \n",
      "8      2015.0                21000.0        7.5          2.35   \n",
      "9      2009.0                11000.0        7.5          2.35   \n",
      "\n",
      "  movie_facebook_likes  \n",
      "0                33000  \n",
      "1                    0  \n",
      "2                85000  \n",
      "3               164000  \n",
      "4                    0  \n",
      "5                24000  \n",
      "6                    0  \n",
      "7                29000  \n",
      "8               118000  \n",
      "9                10000  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(DF.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b46bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                           Avatar\n",
      "1         Pirates of the Caribbean: At World's End\n",
      "2                                          Spectre\n",
      "3                            The Dark Knight Rises\n",
      "4       Star Wars: Episode VII - The Force Awakens\n",
      "                           ...                    \n",
      "5038                       Signed Sealed Delivered\n",
      "5039                                 The Following\n",
      "5040                          A Plague So Pleasant\n",
      "5041                              Shanghai Calling\n",
      "5042                             My Date with Drew\n",
      "Name: movie_title, Length: 5043, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(DF[\"movie_title\"].str.strip()) #Remove white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb347908",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew=DF.rename(columns={\"director_name\":\"director\",\"movie_facebook_likes\":\"facebook_likes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730d1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color           director  num_critic_for_reviews  duration  \\\n",
      "0  Color      JAMES CAMERON                   723.0     178.0   \n",
      "1  Color     GORE VERBINSKI                   302.0     169.0   \n",
      "2  Color         SAM MENDES                   602.0     148.0   \n",
      "3  Color  CHRISTOPHER NOLAN                   813.0     164.0   \n",
      "4    NaN        DOUG WALKER                     NaN       NaN   \n",
      "\n",
      "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
      "0                      0.0                   855.0  Joel David Moore   \n",
      "1                    563.0                  1000.0     Orlando Bloom   \n",
      "2                      0.0                   161.0      Rory Kinnear   \n",
      "3                  22000.0                 23000.0    Christian Bale   \n",
      "4                    131.0                     NaN        Rob Walker   \n",
      "\n",
      "   actor_1_facebook_likes        gross                           genres  ...  \\\n",
      "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
      "1                 40000.0  309404152.0         Action|Adventure|Fantasy  ...   \n",
      "2                 11000.0  200074175.0        Action|Adventure|Thriller  ...   \n",
      "3                 27000.0  448130642.0                  Action|Thriller  ...   \n",
      "4                   131.0          NaN                      Documentary  ...   \n",
      "\n",
      "  num_user_for_reviews language  country  content_rating       budget  \\\n",
      "0               3054.0  English      USA           PG-13  237000000.0   \n",
      "1               1238.0  English      USA           PG-13  300000000.0   \n",
      "2                994.0  English       UK           PG-13  245000000.0   \n",
      "3               2701.0  English      USA           PG-13  250000000.0   \n",
      "4                  NaN      NaN      NaN             NaN          NaN   \n",
      "\n",
      "   title_year actor_2_facebook_likes imdb_score  aspect_ratio facebook_likes  \n",
      "0      2009.0                  936.0        7.9          1.78          33000  \n",
      "1      2007.0                 5000.0        7.1          2.35              0  \n",
      "2      2015.0                  393.0        6.8          2.35          85000  \n",
      "3      2012.0                23000.0        8.5          2.35         164000  \n",
      "4         NaN                   12.0        7.1           NaN              0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dfnew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb59907",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew.to_csv(\"newfilefeb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c79e2",
   "metadata": {},
   "source": [
    "# Handling the missing data and saving it in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a829c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7594b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/Admission_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bab17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
      "0           1      337.0        118.0                4.0  4.5  4.5  9.65   \n",
      "1           2      324.0        107.0                4.0  4.0  4.5  8.87   \n",
      "2           3        NaN        104.0                3.0  3.0  3.5  8.00   \n",
      "3           4      322.0        110.0                3.0  3.5  2.5  8.67   \n",
      "4           5      314.0        103.0                2.0  2.0  3.0  8.21   \n",
      "\n",
      "   Research  Chance of Admit  \n",
      "0         1             0.92  \n",
      "1         1             0.76  \n",
      "2         1             0.72  \n",
      "3         1             0.80  \n",
      "4         0             0.65  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36126bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe7a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR', 'CGPA', 'Research', 'Chance of Admit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7931aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial No.             int64\n",
      "GRE Score            float64\n",
      "TOEFL Score          float64\n",
      "University Rating    float64\n",
      "SOP                  float64\n",
      "LOR                  float64\n",
      "CGPA                 float64\n",
      "Research               int64\n",
      "Chance of Admit      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "939afca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
      "count  500.000000  485.000000   490.000000         485.000000  500.000000   \n",
      "mean   250.500000  316.558763   107.187755           3.121649    3.374000   \n",
      "std    144.481833   11.274704     6.112899           1.146160    0.991004   \n",
      "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
      "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
      "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
      "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
      "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
      "\n",
      "             LOR        CGPA    Research  Chance of Admit  \n",
      "count  500.00000  500.000000  500.000000        500.00000  \n",
      "mean     3.48400    8.576440    0.560000          0.72174  \n",
      "std      0.92545    0.604813    0.496884          0.14114  \n",
      "min      1.00000    6.800000    0.000000          0.34000  \n",
      "25%      3.00000    8.127500    0.000000          0.63000  \n",
      "50%      3.50000    8.560000    1.000000          0.72000  \n",
      "75%      4.00000    9.040000    1.000000          0.82000  \n",
      "max      5.00000    9.920000    1.000000          0.97000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df847ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   count        mean         std     min       25%     50%  \\\n",
      "Serial No.         500.0  250.500000  144.481833    1.00  125.7500  250.50   \n",
      "GRE Score          485.0  316.558763   11.274704  290.00  308.0000  317.00   \n",
      "TOEFL Score        490.0  107.187755    6.112899   92.00  103.0000  107.00   \n",
      "University Rating  485.0    3.121649    1.146160    1.00    2.0000    3.00   \n",
      "SOP                500.0    3.374000    0.991004    1.00    2.5000    3.50   \n",
      "LOR                500.0    3.484000    0.925450    1.00    3.0000    3.50   \n",
      "CGPA               500.0    8.576440    0.604813    6.80    8.1275    8.56   \n",
      "Research           500.0    0.560000    0.496884    0.00    0.0000    1.00   \n",
      "Chance of Admit    500.0    0.721740    0.141140    0.34    0.6300    0.72   \n",
      "\n",
      "                      75%     max  \n",
      "Serial No.         375.25  500.00  \n",
      "GRE Score          325.00  340.00  \n",
      "TOEFL Score        112.00  120.00  \n",
      "University Rating    4.00    5.00  \n",
      "SOP                  4.00    5.00  \n",
      "LOR                  4.00    5.00  \n",
      "CGPA                 9.04    9.92  \n",
      "Research             1.00    1.00  \n",
      "Chance of Admit      0.82    0.97  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe().T) #Here T means Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "534bab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values list before cleaning :\n",
      " Serial No.            0\n",
      "GRE Score            15\n",
      "TOEFL Score          10\n",
      "University Rating    15\n",
      "SOP                   0\n",
      "LOR                   0\n",
      "CGPA                  0\n",
      "Research              0\n",
      "Chance of Admit       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values list before cleaning :\\n\",df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122aae7",
   "metadata": {},
   "source": [
    "#As we can see, there are some column with missing values. We need to impute those missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1241b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Values list after cleaning :\n",
      " Serial No.           0\n",
      "GRE Score            0\n",
      "TOEFL Score          0\n",
      "University Rating    0\n",
      "SOP                  0\n",
      "LOR                  0\n",
      "CGPA                 0\n",
      "Research             0\n",
      "Chance of Admit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"GRE Score\"].fillna(round(df[\"GRE Score\"].mean()),inplace=True)\n",
    "df[\"TOEFL Score\"].fillna(round(df[\"TOEFL Score\"].mean()),inplace=True)\n",
    "df[\"University Rating\"].fillna(df[\"University Rating\"].mode()[0],inplace=True)\n",
    "print(\"NaN Values list after cleaning :\\n\",df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1249b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"admissing_prediction_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef474ba",
   "metadata": {},
   "source": [
    "# Data sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96e3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4247e2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      color      director_name  num_critic_for_reviews  duration  \\\n",
      "0     Color      James Cameron                   723.0     178.0   \n",
      "1     Color     Gore Verbinski                   302.0     169.0   \n",
      "2     Color         Sam Mendes                   602.0     148.0   \n",
      "3     Color  Christopher Nolan                   813.0     164.0   \n",
      "4       NaN        Doug Walker                     NaN       NaN   \n",
      "...     ...                ...                     ...       ...   \n",
      "5038  Color        Scott Smith                     1.0      87.0   \n",
      "5039  Color                NaN                    43.0      43.0   \n",
      "5040  Color   Benjamin Roberds                    13.0      76.0   \n",
      "5041  Color        Daniel Hsia                    14.0     100.0   \n",
      "5042  Color           Jon Gunn                    43.0      90.0   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
      "0                         0.0                   855.0  Joel David Moore   \n",
      "1                       563.0                  1000.0     Orlando Bloom   \n",
      "2                         0.0                   161.0      Rory Kinnear   \n",
      "3                     22000.0                 23000.0    Christian Bale   \n",
      "4                       131.0                     NaN        Rob Walker   \n",
      "...                       ...                     ...               ...   \n",
      "5038                      2.0                   318.0     Daphne Zuniga   \n",
      "5039                      NaN                   319.0     Valorie Curry   \n",
      "5040                      0.0                     0.0     Maxwell Moody   \n",
      "5041                      0.0                   489.0     Daniel Henney   \n",
      "5042                     16.0                    16.0  Brian Herzlinger   \n",
      "\n",
      "      actor_1_facebook_likes        gross                           genres  \\\n",
      "0                     1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
      "1                    40000.0  309404152.0         Action|Adventure|Fantasy   \n",
      "2                    11000.0  200074175.0        Action|Adventure|Thriller   \n",
      "3                    27000.0  448130642.0                  Action|Thriller   \n",
      "4                      131.0          NaN                      Documentary   \n",
      "...                      ...          ...                              ...   \n",
      "5038                   637.0          NaN                     Comedy|Drama   \n",
      "5039                   841.0          NaN     Crime|Drama|Mystery|Thriller   \n",
      "5040                     0.0          NaN            Drama|Horror|Thriller   \n",
      "5041                   946.0      10443.0             Comedy|Drama|Romance   \n",
      "5042                    86.0      85222.0                      Documentary   \n",
      "\n",
      "      ... num_user_for_reviews language  country  content_rating       budget  \\\n",
      "0     ...               3054.0  English      USA           PG-13  237000000.0   \n",
      "1     ...               1238.0  English      USA           PG-13  300000000.0   \n",
      "2     ...                994.0  English       UK           PG-13  245000000.0   \n",
      "3     ...               2701.0  English      USA           PG-13  250000000.0   \n",
      "4     ...                  NaN      NaN      NaN             NaN          NaN   \n",
      "...   ...                  ...      ...      ...             ...          ...   \n",
      "5038  ...                  6.0  English   Canada             NaN          NaN   \n",
      "5039  ...                359.0  English      USA           TV-14          NaN   \n",
      "5040  ...                  3.0  English      USA             NaN       1400.0   \n",
      "5041  ...                  9.0  English      USA           PG-13          NaN   \n",
      "5042  ...                 84.0  English      USA              PG       1100.0   \n",
      "\n",
      "      title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "0         2009.0                  936.0        7.9          1.78   \n",
      "1         2007.0                 5000.0        7.1          2.35   \n",
      "2         2015.0                  393.0        6.8          2.35   \n",
      "3         2012.0                23000.0        8.5          2.35   \n",
      "4            NaN                   12.0        7.1           NaN   \n",
      "...          ...                    ...        ...           ...   \n",
      "5038      2013.0                  470.0        7.7           NaN   \n",
      "5039         NaN                  593.0        7.5         16.00   \n",
      "5040      2013.0                    0.0        6.3           NaN   \n",
      "5041      2012.0                  719.0        6.3          2.35   \n",
      "5042      2004.0                   23.0        6.6          1.85   \n",
      "\n",
      "     movie_facebook_likes  \n",
      "0                   33000  \n",
      "1                       0  \n",
      "2                   85000  \n",
      "3                  164000  \n",
      "4                       0  \n",
      "...                   ...  \n",
      "5038                   84  \n",
      "5039                32000  \n",
      "5040                   16  \n",
      "5041                  660  \n",
      "5042                  456  \n",
      "\n",
      "[5043 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data/movie_metadata.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fcb742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    178.0\n",
      "1    169.0\n",
      "2    148.0\n",
      "3    164.0\n",
      "4      NaN\n",
      "5    132.0\n",
      "6    156.0\n",
      "7    100.0\n",
      "8    141.0\n",
      "9    153.0\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"duration\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f837380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      color     director_name  num_critic_for_reviews  duration  \\\n",
      "2345  Color        Jane Clark                     NaN       7.0   \n",
      "1947  Color               NaN                    12.0       7.0   \n",
      "4079  Color               NaN                    38.0      11.0   \n",
      "4673  Color       Clark Baker                     1.0      14.0   \n",
      "4439  Color  Robert Greenwald                    56.0      20.0   \n",
      "...     ...               ...                     ...       ...   \n",
      "4517  Color               NaN                     2.0       NaN   \n",
      "4609  Color      Wajahat Rauf                     6.0       NaN   \n",
      "4690  Color   Joseph Kosinski                     4.0       NaN   \n",
      "4948  Color         Valentine                     NaN       NaN   \n",
      "4989  Color    Daniel Mellitz                     NaN       NaN   \n",
      "\n",
      "      director_facebook_likes  actor_3_facebook_likes        actor_2_name  \\\n",
      "2345                     23.0                    51.0     Traci Dinwiddie   \n",
      "1947                      NaN                     3.0        John Sparkes   \n",
      "4079                      NaN                     0.0          Seth Green   \n",
      "4673                      0.0                    37.0  Alan Pietruszewski   \n",
      "4439                     21.0                     0.0          Jon Hunter   \n",
      "...                       ...                     ...                 ...   \n",
      "4517                      NaN                   206.0        John Jarratt   \n",
      "4609                      3.0                     4.0         Ayesha Omar   \n",
      "4690                    364.0                   567.0        Lauren Cohan   \n",
      "4948                      0.0                     NaN           Valentine   \n",
      "4989                      0.0                    15.0        Chelse Swain   \n",
      "\n",
      "      actor_1_facebook_likes  gross                           genres  ...  \\\n",
      "2345                   344.0    NaN                    Romance|Short  ...   \n",
      "1947                    45.0    NaN          Animation|Comedy|Family  ...   \n",
      "4079                    11.0    NaN                 Animation|Comedy  ...   \n",
      "4673                   134.0    NaN     Horror|Sci-Fi|Short|Thriller  ...   \n",
      "4439                     0.0    NaN                      Documentary  ...   \n",
      "...                      ...    ...                              ...  ...   \n",
      "4517                   511.0    NaN            Drama|Horror|Thriller  ...   \n",
      "4609                     7.0    NaN                    Comedy|Family  ...   \n",
      "4690                 22000.0    NaN  Action|Adventure|Fantasy|Sci-Fi  ...   \n",
      "4948                    17.0    NaN                          Romance  ...   \n",
      "4989                  1000.0    NaN                     Comedy|Drama  ...   \n",
      "\n",
      "     num_user_for_reviews language    country  content_rating     budget  \\\n",
      "2345                  NaN  English        USA             NaN    13000.0   \n",
      "1947                 12.0  English         UK            TV-G        NaN   \n",
      "4079                 75.0  English        USA           TV-MA        NaN   \n",
      "4673                  3.0  English        USA             NaN        NaN   \n",
      "4439                 70.0  English        USA       Not Rated  1500000.0   \n",
      "...                   ...      ...        ...             ...        ...   \n",
      "4517                  6.0  English  Australia             NaN        NaN   \n",
      "4609                 15.0     Urdu   Pakistan             NaN  1000000.0   \n",
      "4690                 11.0  English        USA             NaN        NaN   \n",
      "4948                  NaN  English        USA           PG-13   125000.0   \n",
      "4989                  3.0  English        USA             NaN        NaN   \n",
      "\n",
      "      title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
      "2345      2007.0                  281.0        5.2          1.85   \n",
      "1947         NaN                    7.0        8.3           NaN   \n",
      "4079         NaN                    0.0        7.8          1.33   \n",
      "4673      2012.0                   93.0        6.2           NaN   \n",
      "4439      2005.0                    0.0        6.8          1.85   \n",
      "...          ...                    ...        ...           ...   \n",
      "4517         NaN                  457.0        7.1          2.00   \n",
      "4609      2015.0                    5.0        7.0           NaN   \n",
      "4690      2014.0                 4000.0        8.1           NaN   \n",
      "4948      2015.0                    0.0        5.1           NaN   \n",
      "4989      2006.0                   36.0        4.7           NaN   \n",
      "\n",
      "     movie_facebook_likes  \n",
      "2345                   30  \n",
      "1947                  834  \n",
      "4079                 1000  \n",
      "4673                   14  \n",
      "4439                    0  \n",
      "...                   ...  \n",
      "4517                  954  \n",
      "4609                  259  \n",
      "4690                 1000  \n",
      "4948                    0  \n",
      "4989                    2  \n",
      "\n",
      "[5043 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "dt=df.sort_values(\"duration\")\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d5f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345     7.0\n",
      "1947     7.0\n",
      "4079    11.0\n",
      "4673    14.0\n",
      "4439    20.0\n",
      "4803    22.0\n",
      "757     22.0\n",
      "816     22.0\n",
      "833     22.0\n",
      "4281    22.0\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dt.duration.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906185d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710    511.0\n",
      "2466    334.0\n",
      "1501    330.0\n",
      "1144    325.0\n",
      "3311    300.0\n",
      "2970    293.0\n",
      "1571    289.0\n",
      "2727    286.0\n",
      "883     280.0\n",
      "1980    271.0\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "DA=df.sort_values(\"duration\",ascending = False) #Now the values in the column duration will be printed in descending order\n",
    "print(DA.duration.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee70921",
   "metadata": {},
   "source": [
    "# Find the mean of Departure delays for every origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5889addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42aa1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Data/flightdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d91b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FL_DATE OP_UNIQUE_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  DEP_DELAY  \\\n",
      "0  2019-01-01                9E               5246    MSP  MKE       33.0   \n",
      "1  2019-01-01                9E               5249    ATL  PHF        8.0   \n",
      "2  2019-01-01                9E               5249    PHF  ATL       -6.0   \n",
      "3  2019-01-01                9E               5250    MSP  CLE       10.0   \n",
      "4  2019-01-01                9E               5254    MSP  RDU       -5.0   \n",
      "\n",
      "   ARR_DELAY  CANCELLED  ACTUAL_ELAPSED_TIME  CARRIER_DELAY  WEATHER_DELAY  \\\n",
      "0        8.0        0.0                 64.0            NaN            NaN   \n",
      "1       -5.0        0.0                 90.0            NaN            NaN   \n",
      "2       -2.0        0.0                121.0            NaN            NaN   \n",
      "3       -5.0        0.0                102.0            NaN            NaN   \n",
      "4      -27.0        0.0                139.0            NaN            NaN   \n",
      "\n",
      "   NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 14  \n",
      "0        NaN             NaN                  NaN          NaN  \n",
      "1        NaN             NaN                  NaN          NaN  \n",
      "2        NaN             NaN                  NaN          NaN  \n",
      "3        NaN             NaN                  NaN          NaN  \n",
      "4        NaN             NaN                  NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd43d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583985, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55af744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGIN\n",
      "ABE    12.208723\n",
      "ABI     5.428571\n",
      "ABQ     3.961062\n",
      "ABR     9.983333\n",
      "ABY     2.783133\n",
      "         ...    \n",
      "VPS     3.480573\n",
      "WRG    11.913793\n",
      "XNA     9.654492\n",
      "YAK    -1.218182\n",
      "YUM    -0.756522\n",
      "Name: DEP_DELAY, Length: 346, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby([\"ORIGIN\"])[\"DEP_DELAY\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21fc15db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGIN\n",
      "MSP    1266.0\n",
      "ATL    1434.0\n",
      "PHF     193.0\n",
      "RIC    1042.0\n",
      "OMA    1245.0\n",
      "        ...  \n",
      "SMX     139.0\n",
      "OGS     268.0\n",
      "PPG      13.0\n",
      "OGD      91.0\n",
      "LYH      34.0\n",
      "Name: DEP_DELAY, Length: 346, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby([\"ORIGIN\"],sort=False)[\"DEP_DELAY\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ed03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df.groupby([\"ORIGIN\"],sort=False)[\"DEP_DELAY\"].mean() #To fetch the one origin details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f524411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEP_DELAY from ATL : 5.76\n"
     ]
    }
   ],
   "source": [
    "print(\"DEP_DELAY from ATL :\",round(dt[\"ATL\"],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b0460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
